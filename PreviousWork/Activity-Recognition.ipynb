{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import sys\n",
    "import time\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the preprocessed data as stored in Numpy-files. Please note that the data has already been split up in a training (training), validation (val), and test subsets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['acc', 'gyr', 'mag']\n",
      "['wrist', 'ankle', 'chest']\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "d_name = 'PAM2'\n",
    "num_classes, sensors, locations, label_names, f_hz, dimensions, path = get_details(d_name)\n",
    "\n",
    "print(sensors)\n",
    "print(locations)\n",
    "print(f_hz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14438, 512, 27)\n",
      "(2180, 512, 27)\n",
      "(200, 512, 27)\n",
      "(14438, 12)\n",
      "(2180, 12)\n",
      "(200, 12)\n"
     ]
    }
   ],
   "source": [
    "X_train0, y_train_binary, X_val0, y_val_binary, X_test0, y_test_binary = load_dataset(d_name, path, num_classes)\n",
    "print(X_train0.shape)\n",
    "print(X_test0.shape)\n",
    "print(X_val0.shape)\n",
    "print(y_train_binary.shape)\n",
    "print(y_test_binary.shape)\n",
    "print(y_val_binary.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## My Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from existing_models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#network_type = 'MLP'\n",
    "network_type = 'CNN'\n",
    "#network_type = 'LSTM'\n",
    "#network_type = 'ConvLSTM'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reshaping data for different models ...\n",
      "CNN\n"
     ]
    }
   ],
   "source": [
    "print('Reshaping data for different models ...')\n",
    "X_train, X_val, X_test = reshape_data(X_train0, X_val0, X_test0, network_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#specifying hyper-parameters\n",
    "batch_size = 256\n",
    "_, win_len, dim = X_train0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building the model ...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 256)               3539200   \n",
      "_________________________________________________________________\n",
      "Bn_1 (BatchNormalization)    (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "Drop_1 (Dropout)             (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "Bn_2 (BatchNormalization)    (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "Drop_2 (Dropout)             (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_out (Dense)            (None, 12)                3084      \n",
      "=================================================================\n",
      "Total params: 3,610,124\n",
      "Trainable params: 3,609,100\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print('building the model ...')\n",
    "if network_type =='CNN' :\n",
    "    model = model_CNN(dim, win_len, num_classes, num_feat_map=32, p=0.3)\n",
    "\n",
    "if network_type =='ConvLSTM':\n",
    "    model = model_ConvLSTM(dim, win_len, num_classes, num_feat_map=32, p=0.3)\n",
    "\n",
    "if network_type =='LSTM':\n",
    "    model = model_LSTM(dim, win_len, num_classes, num_hidden_lstm=32, p=0.3)\n",
    "    \n",
    "if network_type =='MLP': \n",
    "    model = model_MLP(dim, win_len, num_classes, num_hidden_mlp=256, p=0.3)\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model training ...\n",
      "Train on 14438 samples, validate on 200 samples\n",
      "Epoch 1/100\n",
      "14400/14438 [============================>.] - ETA: 0s - loss: 1.0619 - acc: 0.6612\n",
      "Epoch 00001: val_acc improved from -inf to 0.54000, saving model to Models/Conv1D/best_Conv1D_PAM2_1571863899.hdf5\n",
      "14438/14438 [==============================] - 14s 969us/sample - loss: 1.0601 - acc: 0.6617 - val_loss: 1.3415 - val_acc: 0.5400\n",
      "Epoch 2/100\n",
      "14400/14438 [============================>.] - ETA: 0s - loss: 0.1622 - acc: 0.9422\n",
      "Epoch 00002: val_acc improved from 0.54000 to 0.85000, saving model to Models/Conv1D/best_Conv1D_PAM2_1571863899.hdf5\n",
      "14438/14438 [==============================] - 10s 681us/sample - loss: 0.1618 - acc: 0.9423 - val_loss: 0.4116 - val_acc: 0.8500\n",
      "Epoch 3/100\n",
      "14400/14438 [============================>.] - ETA: 0s - loss: 0.0663 - acc: 0.9774\n",
      "Epoch 00003: val_acc improved from 0.85000 to 0.92000, saving model to Models/Conv1D/best_Conv1D_PAM2_1571863899.hdf5\n",
      "14438/14438 [==============================] - 10s 683us/sample - loss: 0.0667 - acc: 0.9771 - val_loss: 0.2434 - val_acc: 0.9200\n",
      "Epoch 4/100\n",
      "14400/14438 [============================>.] - ETA: 0s - loss: 0.0501 - acc: 0.9824\n",
      "Epoch 00004: val_acc improved from 0.92000 to 0.93500, saving model to Models/Conv1D/best_Conv1D_PAM2_1571863899.hdf5\n",
      "14438/14438 [==============================] - 10s 684us/sample - loss: 0.0501 - acc: 0.9824 - val_loss: 0.2229 - val_acc: 0.9350\n",
      "Epoch 5/100\n",
      "14400/14438 [============================>.] - ETA: 0s - loss: 0.0191 - acc: 0.9938\n",
      "Epoch 00005: val_acc did not improve from 0.93500\n",
      "14438/14438 [==============================] - 10s 683us/sample - loss: 0.0191 - acc: 0.9938 - val_loss: 0.2510 - val_acc: 0.9300\n",
      "Epoch 6/100\n",
      "14400/14438 [============================>.] - ETA: 0s - loss: 0.0111 - acc: 0.9963\n",
      "Epoch 00006: val_acc did not improve from 0.93500\n",
      "14438/14438 [==============================] - 10s 693us/sample - loss: 0.0111 - acc: 0.9963 - val_loss: 0.2380 - val_acc: 0.9350\n",
      "Epoch 7/100\n",
      "14400/14438 [============================>.] - ETA: 0s - loss: 0.0138 - acc: 0.9952\n",
      "Epoch 00007: val_acc improved from 0.93500 to 0.94500, saving model to Models/Conv1D/best_Conv1D_PAM2_1571863899.hdf5\n",
      "14438/14438 [==============================] - 10s 690us/sample - loss: 0.0138 - acc: 0.9952 - val_loss: 0.2200 - val_acc: 0.9450\n",
      "Epoch 8/100\n",
      "14400/14438 [============================>.] - ETA: 0s - loss: 0.0058 - acc: 0.9981\n",
      "Epoch 00008: val_acc did not improve from 0.94500\n",
      "14438/14438 [==============================] - 10s 684us/sample - loss: 0.0058 - acc: 0.9981 - val_loss: 0.1680 - val_acc: 0.9400\n",
      "Epoch 9/100\n",
      "14400/14438 [============================>.] - ETA: 0s - loss: 0.0062 - acc: 0.9979\n",
      "Epoch 00009: val_acc did not improve from 0.94500\n",
      "14438/14438 [==============================] - 10s 686us/sample - loss: 0.0062 - acc: 0.9979 - val_loss: 0.3513 - val_acc: 0.9250\n",
      "Epoch 10/100\n",
      "14400/14438 [============================>.] - ETA: 0s - loss: 0.0061 - acc: 0.9983\n",
      "Epoch 00010: val_acc did not improve from 0.94500\n",
      "14438/14438 [==============================] - 10s 684us/sample - loss: 0.0061 - acc: 0.9983 - val_loss: 0.3061 - val_acc: 0.9000\n",
      "Epoch 11/100\n",
      "14400/14438 [============================>.] - ETA: 0s - loss: 0.0055 - acc: 0.9978\n",
      "Epoch 00011: val_acc did not improve from 0.94500\n",
      "14438/14438 [==============================] - 10s 689us/sample - loss: 0.0055 - acc: 0.9979 - val_loss: 0.2792 - val_acc: 0.9200\n",
      "Epoch 12/100\n",
      "14400/14438 [============================>.] - ETA: 0s - loss: 0.0058 - acc: 0.9979\n",
      "Epoch 00012: val_acc did not improve from 0.94500\n",
      "14438/14438 [==============================] - 10s 692us/sample - loss: 0.0058 - acc: 0.9979 - val_loss: 0.2393 - val_acc: 0.9300\n",
      "Epoch 13/100\n",
      "14400/14438 [============================>.] - ETA: 0s - loss: 0.0097 - acc: 0.9969\n",
      "Epoch 00013: val_acc did not improve from 0.94500\n",
      "14438/14438 [==============================] - 10s 691us/sample - loss: 0.0096 - acc: 0.9969 - val_loss: 0.4135 - val_acc: 0.9250\n",
      "Epoch 14/100\n",
      "14400/14438 [============================>.] - ETA: 0s - loss: 0.0099 - acc: 0.9963\n",
      "Epoch 00014: val_acc did not improve from 0.94500\n",
      "14438/14438 [==============================] - 10s 685us/sample - loss: 0.0099 - acc: 0.9963 - val_loss: 0.5286 - val_acc: 0.9200\n",
      "Epoch 15/100\n",
      "14400/14438 [============================>.] - ETA: 0s - loss: 0.0031 - acc: 0.9990\n",
      "Epoch 00015: val_acc improved from 0.94500 to 0.95500, saving model to Models/Conv1D/best_Conv1D_PAM2_1571863899.hdf5\n",
      "14438/14438 [==============================] - 10s 690us/sample - loss: 0.0031 - acc: 0.9990 - val_loss: 0.1520 - val_acc: 0.9550\n",
      "Epoch 16/100\n",
      "14400/14438 [============================>.] - ETA: 0s - loss: 0.0013 - acc: 0.9997\n",
      "Epoch 00016: val_acc did not improve from 0.95500\n",
      "14438/14438 [==============================] - 10s 685us/sample - loss: 0.0013 - acc: 0.9997 - val_loss: 0.3396 - val_acc: 0.9350\n",
      "Epoch 17/100\n",
      "14400/14438 [============================>.] - ETA: 0s - loss: 8.2564e-04 - acc: 0.9999\n",
      "Epoch 00017: val_acc did not improve from 0.95500\n",
      "14438/14438 [==============================] - 10s 687us/sample - loss: 8.2349e-04 - acc: 0.9999 - val_loss: 0.2370 - val_acc: 0.9500\n",
      "Epoch 18/100\n",
      "14400/14438 [============================>.] - ETA: 0s - loss: 0.0012 - acc: 0.9996\n",
      "Epoch 00018: val_acc did not improve from 0.95500\n",
      "14438/14438 [==============================] - 10s 683us/sample - loss: 0.0012 - acc: 0.9996 - val_loss: 0.3875 - val_acc: 0.9300\n",
      "Epoch 19/100\n",
      "14400/14438 [============================>.] - ETA: 0s - loss: 0.0032 - acc: 0.9987\n",
      "Epoch 00019: val_acc improved from 0.95500 to 0.98500, saving model to Models/Conv1D/best_Conv1D_PAM2_1571863899.hdf5\n",
      "14438/14438 [==============================] - 10s 687us/sample - loss: 0.0032 - acc: 0.9988 - val_loss: 0.0786 - val_acc: 0.9850\n",
      "Epoch 20/100\n",
      "14400/14438 [============================>.] - ETA: 0s - loss: 0.0066 - acc: 0.9977\n",
      "Epoch 00020: val_acc did not improve from 0.98500\n",
      "14438/14438 [==============================] - 10s 685us/sample - loss: 0.0066 - acc: 0.9977 - val_loss: 0.2298 - val_acc: 0.9050\n",
      "Epoch 21/100\n",
      "14400/14438 [============================>.] - ETA: 0s - loss: 0.0089 - acc: 0.9969\n",
      "Epoch 00021: val_acc did not improve from 0.98500\n",
      "14438/14438 [==============================] - 10s 679us/sample - loss: 0.0089 - acc: 0.9970 - val_loss: 0.7862 - val_acc: 0.8800\n",
      "Epoch 22/100\n",
      "14400/14438 [============================>.] - ETA: 0s - loss: 0.0030 - acc: 0.9992\n",
      "Epoch 00022: val_acc did not improve from 0.98500\n",
      "14438/14438 [==============================] - 10s 680us/sample - loss: 0.0030 - acc: 0.9992 - val_loss: 0.2616 - val_acc: 0.9500\n",
      "Epoch 23/100\n",
      "14400/14438 [============================>.] - ETA: 0s - loss: 0.0037 - acc: 0.9985\n",
      "Epoch 00023: val_acc did not improve from 0.98500\n",
      "14438/14438 [==============================] - 10s 679us/sample - loss: 0.0038 - acc: 0.9984 - val_loss: 0.4163 - val_acc: 0.9400\n",
      "Epoch 24/100\n",
      "14400/14438 [============================>.] - ETA: 0s - loss: 0.0080 - acc: 0.9979\n",
      "Epoch 00024: val_acc did not improve from 0.98500\n",
      "14438/14438 [==============================] - 10s 679us/sample - loss: 0.0080 - acc: 0.9979 - val_loss: 0.1277 - val_acc: 0.9550\n",
      "Epoch 25/100\n",
      "14400/14438 [============================>.] - ETA: 0s - loss: 0.0085 - acc: 0.9985\n",
      "Epoch 00025: val_acc did not improve from 0.98500\n",
      "14438/14438 [==============================] - 10s 689us/sample - loss: 0.0085 - acc: 0.9985 - val_loss: 0.6416 - val_acc: 0.9250\n",
      "Epoch 26/100\n",
      "14400/14438 [============================>.] - ETA: 0s - loss: 0.0079 - acc: 0.9975\n",
      "Epoch 00026: val_acc did not improve from 0.98500\n",
      "14438/14438 [==============================] - 10s 685us/sample - loss: 0.0079 - acc: 0.9975 - val_loss: 0.2556 - val_acc: 0.9600\n",
      "Epoch 27/100\n",
      "14400/14438 [============================>.] - ETA: 0s - loss: 0.0049 - acc: 0.9982\n",
      "Epoch 00027: val_acc did not improve from 0.98500\n",
      "14438/14438 [==============================] - 10s 687us/sample - loss: 0.0049 - acc: 0.9982 - val_loss: 0.3109 - val_acc: 0.9450\n",
      "Epoch 28/100\n",
      "14400/14438 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.9994\n",
      "Epoch 00028: val_acc did not improve from 0.98500\n",
      "14438/14438 [==============================] - 10s 684us/sample - loss: 0.0019 - acc: 0.9994 - val_loss: 0.2494 - val_acc: 0.9500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/100\n",
      "14400/14438 [============================>.] - ETA: 0s - loss: 4.8581e-04 - acc: 0.9999\n",
      "Epoch 00029: val_acc did not improve from 0.98500\n",
      "14438/14438 [==============================] - 10s 682us/sample - loss: 4.8457e-04 - acc: 0.9999 - val_loss: 0.2230 - val_acc: 0.9500\n",
      "Epoch 30/100\n",
      "14400/14438 [============================>.] - ETA: 0s - loss: 4.9182e-04 - acc: 0.9999\n",
      "Epoch 00030: val_acc did not improve from 0.98500\n",
      "14438/14438 [==============================] - 10s 689us/sample - loss: 4.9214e-04 - acc: 0.9999 - val_loss: 0.2658 - val_acc: 0.9450\n",
      "Epoch 31/100\n",
      "14400/14438 [============================>.] - ETA: 0s - loss: 2.2144e-04 - acc: 1.0000\n",
      "Epoch 00031: val_acc did not improve from 0.98500\n",
      "14438/14438 [==============================] - 10s 679us/sample - loss: 2.2090e-04 - acc: 1.0000 - val_loss: 0.2709 - val_acc: 0.9500\n",
      "Epoch 32/100\n",
      "14400/14438 [============================>.] - ETA: 0s - loss: 9.0965e-05 - acc: 1.0000\n",
      "Epoch 00032: val_acc did not improve from 0.98500\n",
      "14438/14438 [==============================] - 10s 694us/sample - loss: 9.0726e-05 - acc: 1.0000 - val_loss: 0.2990 - val_acc: 0.9500\n",
      "Epoch 33/100\n",
      "14400/14438 [============================>.] - ETA: 0s - loss: 7.7031e-05 - acc: 1.0000\n",
      "Epoch 00033: val_acc did not improve from 0.98500\n",
      "14438/14438 [==============================] - 10s 684us/sample - loss: 7.6832e-05 - acc: 1.0000 - val_loss: 0.2960 - val_acc: 0.9400\n",
      "Epoch 34/100\n",
      " 9300/14438 [==================>...........] - ETA: 3s - loss: 6.7420e-05 - acc: 1.0000"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-91-5aa4bc1b7b84>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m           \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m           \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val_binary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m           callbacks=[tensorboard, checkpoint])\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'final_{name}.hdf5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    778\u001b[0m           \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m           \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m           steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3291\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3292\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3293\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3294\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print('model training ...')\n",
    "epochs = 10\n",
    "model.compile(loss=tensorflow.keras.losses.categorical_crossentropy,\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_dir = f'Models/{d_name}'\n",
    "\n",
    "name = '{}_d{}_bn{}_{}'.format(network_type, d, b, int(time.time()))\n",
    "tensorboard = TensorBoard(log_dir = 'logs/{}'.format(name))\n",
    "\n",
    "if not os.path.exists(model_dir):\n",
    "    os.makedirs(model_dir)\n",
    "\n",
    "# checkpoint\n",
    "filepath= f\"best_{name}.hdf5\"\n",
    "chk_path = os.path.join(model_dir, filepath)\n",
    "checkpoint = ModelCheckpoint(chk_path, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "model.fit(X_train, y_train_binary,\n",
    "          batch_size=300,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          shuffle=True,\n",
    "          validation_data=(X_val, y_val_binary),\n",
    "          callbacks=[tensorboard, checkpoint])\n",
    "\n",
    "model.save(f'final_{name}.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/vikranth/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /home/vikranth/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /home/vikranth/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:97: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "model = load_model(chk_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[198   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0 198  24   0   0   0   0   0   0   0   0   0]\n",
      " [  0   5 167   0   0   0   0   0   0   1   7   0]\n",
      " [  0   0   0 269   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0 198   0   0   0   5   0   0   0]\n",
      " [  0   0   0   8   0 193   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0 219   0   0   0   0   0]\n",
      " [  0   0   0   3   0   0   0  76   0   0   0   0]\n",
      " [  0   0   0   4   0   0   0   2  68   0   0   0]\n",
      " [  0   2   0   0   0  13   0   0   0 176  10   0]\n",
      " [  0   0   7   0   0   0   0   0   0   4 274   0]\n",
      " [  0   0   0   0   1   0   0   0   0   0   0  48]]\n",
      "the mean-f1 score: 0.9561\n",
      "accuracy is: 0.9560\n"
     ]
    }
   ],
   "source": [
    "y_pred = np.argmax(model.predict(X_test), axis=1)\n",
    "y_true = np.argmax(y_test_binary, axis=1)\n",
    "cf_matrix = confusion_matrix(y_true, y_pred)\n",
    "print(cf_matrix)\n",
    "class_wise_f1 = f1_score(y_true, y_pred, average=None)\n",
    "print('the mean-f1 score: {:.4f}'.format(np.mean(class_wise_f1)))\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "print('accuracy is: {:.4f}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All Cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reshaping data for different models ...\n",
      "MLP\n",
      "building the model ...\n",
      "Model: \"MLP\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 256)               3539200   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_out (Dense)            (None, 12)                3084      \n",
      "=================================================================\n",
      "Total params: 3,608,076\n",
      "Trainable params: 3,608,076\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "model training ...\n",
      "Train on 14438 samples, validate on 200 samples\n",
      "Epoch 1/10\n",
      "13800/14438 [===========================>..] - ETA: 0s - loss: 29.8426 - acc: 0.5314\n",
      "Epoch 00001: val_acc improved from -inf to 0.67000, saving model to Models/PAM2/best_MLP_dFalse_bnFalse.hdf5\n",
      "14438/14438 [==============================] - 2s 153us/sample - loss: 28.6015 - acc: 0.5427 - val_loss: 4.8839 - val_acc: 0.6700\n",
      "Epoch 2/10\n",
      "14400/14438 [============================>.] - ETA: 0s - loss: 0.8322 - acc: 0.8597\n",
      "Epoch 00002: val_acc did not improve from 0.67000\n",
      "14438/14438 [==============================] - 1s 53us/sample - loss: 0.8308 - acc: 0.8598 - val_loss: 4.3210 - val_acc: 0.6550\n",
      "Epoch 3/10\n",
      "14100/14438 [============================>.] - ETA: 0s - loss: 0.3958 - acc: 0.9200\n",
      "Epoch 00003: val_acc improved from 0.67000 to 0.77000, saving model to Models/PAM2/best_MLP_dFalse_bnFalse.hdf5\n",
      "14438/14438 [==============================] - 1s 60us/sample - loss: 0.3906 - acc: 0.9206 - val_loss: 2.0257 - val_acc: 0.7700\n",
      "Epoch 4/10\n",
      "14400/14438 [============================>.] - ETA: 0s - loss: 0.1704 - acc: 0.9562\n",
      "Epoch 00004: val_acc did not improve from 0.77000\n",
      "14438/14438 [==============================] - 1s 43us/sample - loss: 0.1706 - acc: 0.9562 - val_loss: 2.9275 - val_acc: 0.7500\n",
      "Epoch 5/10\n",
      "14100/14438 [============================>.] - ETA: 0s - loss: 0.1166 - acc: 0.9679\n",
      "Epoch 00005: val_acc improved from 0.77000 to 0.79500, saving model to Models/PAM2/best_MLP_dFalse_bnFalse.hdf5\n",
      "14438/14438 [==============================] - 1s 52us/sample - loss: 0.1153 - acc: 0.9683 - val_loss: 2.1382 - val_acc: 0.7950\n",
      "Epoch 6/10\n",
      "14100/14438 [============================>.] - ETA: 0s - loss: 0.0452 - acc: 0.9865\n",
      "Epoch 00006: val_acc did not improve from 0.79500\n",
      "14438/14438 [==============================] - 1s 48us/sample - loss: 0.0446 - acc: 0.9866 - val_loss: 2.3591 - val_acc: 0.7750\n",
      "Epoch 7/10\n",
      "13500/14438 [===========================>..] - ETA: 0s - loss: 0.0234 - acc: 0.9918\n",
      "Epoch 00007: val_acc did not improve from 0.79500\n",
      "14438/14438 [==============================] - 1s 44us/sample - loss: 0.0239 - acc: 0.9916 - val_loss: 2.5605 - val_acc: 0.7600\n",
      "Epoch 8/10\n",
      "14100/14438 [============================>.] - ETA: 0s - loss: 0.0298 - acc: 0.9906\n",
      "Epoch 00008: val_acc did not improve from 0.79500\n",
      "14438/14438 [==============================] - 1s 50us/sample - loss: 0.0295 - acc: 0.9907 - val_loss: 2.4243 - val_acc: 0.7900\n",
      "Epoch 9/10\n",
      "13200/14438 [==========================>...] - ETA: 0s - loss: 0.0171 - acc: 0.9938\n",
      "Epoch 00009: val_acc did not improve from 0.79500\n",
      "14438/14438 [==============================] - 1s 46us/sample - loss: 0.0167 - acc: 0.9938 - val_loss: 2.6260 - val_acc: 0.7550\n",
      "Epoch 10/10\n",
      "14400/14438 [============================>.] - ETA: 0s - loss: 0.0104 - acc: 0.9965\n",
      "Epoch 00010: val_acc did not improve from 0.79500\n",
      "14438/14438 [==============================] - 1s 43us/sample - loss: 0.0104 - acc: 0.9965 - val_loss: 2.5983 - val_acc: 0.7400\n",
      "Reshaping data for different models ...\n",
      "MLP\n",
      "building the model ...\n",
      "Model: \"MLP\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 256)               3539200   \n",
      "_________________________________________________________________\n",
      "Drop_1 (Dropout)             (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "Drop_2 (Dropout)             (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_out (Dense)            (None, 12)                3084      \n",
      "=================================================================\n",
      "Total params: 3,608,076\n",
      "Trainable params: 3,608,076\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "model training ...\n",
      "Train on 14438 samples, validate on 200 samples\n",
      "Epoch 1/10\n",
      "14100/14438 [============================>.] - ETA: 0s - loss: 18.0844 - acc: 0.2970\n",
      "Epoch 00001: val_acc improved from -inf to 0.24000, saving model to Models/PAM2/best_MLP_dTrue_bnFalse.hdf5\n",
      "14438/14438 [==============================] - 2s 145us/sample - loss: 17.7089 - acc: 0.2971 - val_loss: 3.5315 - val_acc: 0.2400\n",
      "Epoch 2/10\n",
      "14100/14438 [============================>.] - ETA: 0s - loss: 2.0739 - acc: 0.3172\n",
      "Epoch 00002: val_acc improved from 0.24000 to 0.31000, saving model to Models/PAM2/best_MLP_dTrue_bnFalse.hdf5\n",
      "14438/14438 [==============================] - 1s 52us/sample - loss: 2.0734 - acc: 0.3175 - val_loss: 3.1793 - val_acc: 0.3100\n",
      "Epoch 3/10\n",
      "13200/14438 [==========================>...] - ETA: 0s - loss: 1.9306 - acc: 0.3487\n",
      "Epoch 00003: val_acc improved from 0.31000 to 0.34000, saving model to Models/PAM2/best_MLP_dTrue_bnFalse.hdf5\n",
      "14438/14438 [==============================] - 1s 51us/sample - loss: 1.9239 - acc: 0.3508 - val_loss: 2.9742 - val_acc: 0.3400\n",
      "Epoch 4/10\n",
      "14400/14438 [============================>.] - ETA: 0s - loss: 1.8005 - acc: 0.3921\n",
      "Epoch 00004: val_acc did not improve from 0.34000\n",
      "14438/14438 [==============================] - 1s 45us/sample - loss: 1.8003 - acc: 0.3920 - val_loss: 2.9965 - val_acc: 0.3250\n",
      "Epoch 5/10\n",
      "14400/14438 [============================>.] - ETA: 0s - loss: 1.7211 - acc: 0.4242\n",
      "Epoch 00005: val_acc improved from 0.34000 to 0.40000, saving model to Models/PAM2/best_MLP_dTrue_bnFalse.hdf5\n",
      "14438/14438 [==============================] - 1s 52us/sample - loss: 1.7209 - acc: 0.4243 - val_loss: 2.3538 - val_acc: 0.4000\n",
      "Epoch 6/10\n",
      "13800/14438 [===========================>..] - ETA: 0s - loss: 1.6962 - acc: 0.4342\n",
      "Epoch 00006: val_acc improved from 0.40000 to 0.40500, saving model to Models/PAM2/best_MLP_dTrue_bnFalse.hdf5\n",
      "14438/14438 [==============================] - 1s 53us/sample - loss: 1.6930 - acc: 0.4337 - val_loss: 2.6720 - val_acc: 0.4050\n",
      "Epoch 7/10\n",
      "13800/14438 [===========================>..] - ETA: 0s - loss: 1.6669 - acc: 0.4291\n",
      "Epoch 00007: val_acc did not improve from 0.40500\n",
      "14438/14438 [==============================] - 1s 46us/sample - loss: 1.6632 - acc: 0.4295 - val_loss: 2.3530 - val_acc: 0.3900\n",
      "Epoch 8/10\n",
      "13500/14438 [===========================>..] - ETA: 0s - loss: 1.6300 - acc: 0.4419\n",
      "Epoch 00008: val_acc improved from 0.40500 to 0.43500, saving model to Models/PAM2/best_MLP_dTrue_bnFalse.hdf5\n",
      "14438/14438 [==============================] - 1s 48us/sample - loss: 1.6225 - acc: 0.4438 - val_loss: 2.3844 - val_acc: 0.4350\n",
      "Epoch 9/10\n",
      "13800/14438 [===========================>..] - ETA: 0s - loss: 1.5787 - acc: 0.4520\n",
      "Epoch 00009: val_acc did not improve from 0.43500\n",
      "14438/14438 [==============================] - 1s 45us/sample - loss: 1.5796 - acc: 0.4510 - val_loss: 2.3045 - val_acc: 0.3800\n",
      "Epoch 10/10\n",
      "13800/14438 [===========================>..] - ETA: 0s - loss: 1.5485 - acc: 0.4567\n",
      "Epoch 00010: val_acc did not improve from 0.43500\n",
      "14438/14438 [==============================] - 1s 45us/sample - loss: 1.5476 - acc: 0.4564 - val_loss: 2.3258 - val_acc: 0.4200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vikranth/anaconda3/envs/tensorflow/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reshaping data for different models ...\n",
      "MLP\n",
      "building the model ...\n",
      "Model: \"MLP\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 256)               3539200   \n",
      "_________________________________________________________________\n",
      "Bn_1 (BatchNormalization)    (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "Bn_2 (BatchNormalization)    (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dense_out (Dense)            (None, 12)                3084      \n",
      "=================================================================\n",
      "Total params: 3,610,124\n",
      "Trainable params: 3,609,100\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n",
      "None\n",
      "model training ...\n",
      "Train on 14438 samples, validate on 200 samples\n",
      "Epoch 1/10\n",
      "14100/14438 [============================>.] - ETA: 0s - loss: 0.5890 - acc: 0.8296\n",
      "Epoch 00001: val_acc improved from -inf to 0.53500, saving model to Models/PAM2/best_MLP_dFalse_bnTrue.hdf5\n",
      "14438/14438 [==============================] - 3s 183us/sample - loss: 0.5813 - acc: 0.8319 - val_loss: 1.9137 - val_acc: 0.5350\n",
      "Epoch 2/10\n",
      "13800/14438 [===========================>..] - ETA: 0s - loss: 0.1241 - acc: 0.9712\n",
      "Epoch 00002: val_acc improved from 0.53500 to 0.55000, saving model to Models/PAM2/best_MLP_dFalse_bnTrue.hdf5\n",
      "14438/14438 [==============================] - 1s 55us/sample - loss: 0.1223 - acc: 0.9717 - val_loss: 1.4570 - val_acc: 0.5500\n",
      "Epoch 3/10\n",
      "13500/14438 [===========================>..] - ETA: 0s - loss: 0.0464 - acc: 0.9919\n",
      "Epoch 00003: val_acc did not improve from 0.55000\n",
      "14438/14438 [==============================] - 1s 47us/sample - loss: 0.0453 - acc: 0.9922 - val_loss: 1.5494 - val_acc: 0.5350\n",
      "Epoch 4/10\n",
      "13500/14438 [===========================>..] - ETA: 0s - loss: 0.0210 - acc: 0.9978\n",
      "Epoch 00004: val_acc improved from 0.55000 to 0.66000, saving model to Models/PAM2/best_MLP_dFalse_bnTrue.hdf5\n",
      "14438/14438 [==============================] - 1s 62us/sample - loss: 0.0208 - acc: 0.9979 - val_loss: 1.0783 - val_acc: 0.6600\n",
      "Epoch 5/10\n",
      "14400/14438 [============================>.] - ETA: 0s - loss: 0.0111 - acc: 0.9991\n",
      "Epoch 00005: val_acc improved from 0.66000 to 0.77000, saving model to Models/PAM2/best_MLP_dFalse_bnTrue.hdf5\n",
      "14438/14438 [==============================] - 1s 53us/sample - loss: 0.0111 - acc: 0.9991 - val_loss: 0.8395 - val_acc: 0.7700\n",
      "Epoch 6/10\n",
      "14100/14438 [============================>.] - ETA: 0s - loss: 0.0068 - acc: 0.9998\n",
      "Epoch 00006: val_acc improved from 0.77000 to 0.79000, saving model to Models/PAM2/best_MLP_dFalse_bnTrue.hdf5\n",
      "14438/14438 [==============================] - 1s 60us/sample - loss: 0.0068 - acc: 0.9998 - val_loss: 0.7589 - val_acc: 0.7900\n",
      "Epoch 7/10\n",
      "14400/14438 [============================>.] - ETA: 0s - loss: 0.0076 - acc: 0.9994\n",
      "Epoch 00007: val_acc did not improve from 0.79000\n",
      "14438/14438 [==============================] - 1s 48us/sample - loss: 0.0076 - acc: 0.9994 - val_loss: 0.7846 - val_acc: 0.7900\n",
      "Epoch 8/10\n",
      "14100/14438 [============================>.] - ETA: 0s - loss: 0.0046 - acc: 0.9999\n",
      "Epoch 00008: val_acc did not improve from 0.79000\n",
      "14438/14438 [==============================] - 1s 48us/sample - loss: 0.0046 - acc: 0.9999 - val_loss: 0.8493 - val_acc: 0.7850\n",
      "Epoch 9/10\n",
      "13500/14438 [===========================>..] - ETA: 0s - loss: 0.0093 - acc: 0.9984\n",
      "Epoch 00009: val_acc improved from 0.79000 to 0.80500, saving model to Models/PAM2/best_MLP_dFalse_bnTrue.hdf5\n",
      "14438/14438 [==============================] - 1s 50us/sample - loss: 0.0092 - acc: 0.9984 - val_loss: 0.8838 - val_acc: 0.8050\n",
      "Epoch 10/10\n",
      "14100/14438 [============================>.] - ETA: 0s - loss: 0.0039 - acc: 0.9998\n",
      "Epoch 00010: val_acc did not improve from 0.80500\n",
      "14438/14438 [==============================] - 1s 50us/sample - loss: 0.0039 - acc: 0.9998 - val_loss: 1.1778 - val_acc: 0.7600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vikranth/anaconda3/envs/tensorflow/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reshaping data for different models ...\n",
      "MLP\n",
      "building the model ...\n",
      "Model: \"MLP\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 256)               3539200   \n",
      "_________________________________________________________________\n",
      "Bn_1 (BatchNormalization)    (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "Drop_1 (Dropout)             (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "Bn_2 (BatchNormalization)    (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "Drop_2 (Dropout)             (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_out (Dense)            (None, 12)                3084      \n",
      "=================================================================\n",
      "Total params: 3,610,124\n",
      "Trainable params: 3,609,100\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n",
      "None\n",
      "model training ...\n",
      "Train on 14438 samples, validate on 200 samples\n",
      "Epoch 1/10\n",
      "13500/14438 [===========================>..] - ETA: 0s - loss: 0.9299 - acc: 0.7156\n",
      "Epoch 00001: val_acc improved from -inf to 0.45000, saving model to Models/PAM2/best_MLP_dTrue_bnTrue.hdf5\n",
      "14438/14438 [==============================] - 3s 190us/sample - loss: 0.9010 - acc: 0.7245 - val_loss: 2.1930 - val_acc: 0.4500\n",
      "Epoch 2/10\n",
      "14100/14438 [============================>.] - ETA: 0s - loss: 0.3724 - acc: 0.8845\n",
      "Epoch 00002: val_acc improved from 0.45000 to 0.66500, saving model to Models/PAM2/best_MLP_dTrue_bnTrue.hdf5\n",
      "14438/14438 [==============================] - 1s 52us/sample - loss: 0.3697 - acc: 0.8859 - val_loss: 1.0409 - val_acc: 0.6650\n",
      "Epoch 3/10\n",
      "13800/14438 [===========================>..] - ETA: 0s - loss: 0.2079 - acc: 0.9376\n",
      "Epoch 00003: val_acc did not improve from 0.66500\n",
      "14438/14438 [==============================] - 1s 58us/sample - loss: 0.2060 - acc: 0.9384 - val_loss: 0.9993 - val_acc: 0.6350\n",
      "Epoch 4/10\n",
      "14400/14438 [============================>.] - ETA: 0s - loss: 0.1336 - acc: 0.9624\n",
      "Epoch 00004: val_acc improved from 0.66500 to 0.82500, saving model to Models/PAM2/best_MLP_dTrue_bnTrue.hdf5\n",
      "14438/14438 [==============================] - 1s 59us/sample - loss: 0.1337 - acc: 0.9623 - val_loss: 0.5632 - val_acc: 0.8250\n",
      "Epoch 5/10\n",
      "14400/14438 [============================>.] - ETA: 0s - loss: 0.0970 - acc: 0.9717\n",
      "Epoch 00005: val_acc did not improve from 0.82500\n",
      "14438/14438 [==============================] - 1s 49us/sample - loss: 0.0974 - acc: 0.9715 - val_loss: 0.5910 - val_acc: 0.7950\n",
      "Epoch 6/10\n",
      "13800/14438 [===========================>..] - ETA: 0s - loss: 0.0873 - acc: 0.9748\n",
      "Epoch 00006: val_acc improved from 0.82500 to 0.84000, saving model to Models/PAM2/best_MLP_dTrue_bnTrue.hdf5\n",
      "14438/14438 [==============================] - 1s 64us/sample - loss: 0.0877 - acc: 0.9747 - val_loss: 0.5797 - val_acc: 0.8400\n",
      "Epoch 7/10\n",
      "13800/14438 [===========================>..] - ETA: 0s - loss: 0.0670 - acc: 0.9808\n",
      "Epoch 00007: val_acc improved from 0.84000 to 0.87000, saving model to Models/PAM2/best_MLP_dTrue_bnTrue.hdf5\n",
      "14438/14438 [==============================] - 1s 64us/sample - loss: 0.0665 - acc: 0.9811 - val_loss: 0.4134 - val_acc: 0.8700\n",
      "Epoch 8/10\n",
      "14100/14438 [============================>.] - ETA: 0s - loss: 0.0552 - acc: 0.9837\n",
      "Epoch 00008: val_acc did not improve from 0.87000\n",
      "14438/14438 [==============================] - 1s 63us/sample - loss: 0.0553 - acc: 0.9836 - val_loss: 0.5238 - val_acc: 0.8550\n",
      "Epoch 9/10\n",
      "14400/14438 [============================>.] - ETA: 0s - loss: 0.0468 - acc: 0.9864\n",
      "Epoch 00009: val_acc did not improve from 0.87000\n",
      "14438/14438 [==============================] - 1s 63us/sample - loss: 0.0468 - acc: 0.9864 - val_loss: 0.5935 - val_acc: 0.8600\n",
      "Epoch 10/10\n",
      "14400/14438 [============================>.] - ETA: 0s - loss: 0.0383 - acc: 0.9892\n",
      "Epoch 00010: val_acc did not improve from 0.87000\n",
      "14438/14438 [==============================] - 1s 49us/sample - loss: 0.0383 - acc: 0.9892 - val_loss: 0.4964 - val_acc: 0.8450\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vikranth/anaconda3/envs/tensorflow/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reshaping data for different models ...\n",
      "CNN\n",
      "building the model ...\n",
      "Model: \"CNN\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Conv_1 (Conv2D)              (None, 27, 512, 32)       128       \n",
      "_________________________________________________________________\n",
      "Max_pool_1 (MaxPooling2D)    (None, 27, 256, 32)       0         \n",
      "_________________________________________________________________\n",
      "Conv_2 (Conv2D)              (None, 27, 256, 32)       3104      \n",
      "_________________________________________________________________\n",
      "Max_pool_2 (MaxPooling2D)    (None, 27, 128, 32)       0         \n",
      "_________________________________________________________________\n",
      "Flatten_1 (Flatten)          (None, 110592)            0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 32)                3538976   \n",
      "_________________________________________________________________\n",
      "dense_out (Dense)            (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 3,542,604\n",
      "Trainable params: 3,542,604\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "model training ...\n",
      "Train on 14438 samples, validate on 200 samples\n",
      "Epoch 1/10\n",
      "14400/14438 [============================>.] - ETA: 0s - loss: 6.4706 - acc: 0.1003\n",
      "Epoch 00001: val_acc improved from -inf to 0.08500, saving model to Models/PAM2/best_CNN_dFalse_bnFalse.hdf5\n",
      "14438/14438 [==============================] - 6s 448us/sample - loss: 6.4599 - acc: 0.1004 - val_loss: 2.4141 - val_acc: 0.0850\n",
      "Epoch 2/10\n",
      "14400/14438 [============================>.] - ETA: 0s - loss: 2.3230 - acc: 0.1501\n",
      "Epoch 00002: val_acc improved from 0.08500 to 0.15000, saving model to Models/PAM2/best_CNN_dFalse_bnFalse.hdf5\n",
      "14438/14438 [==============================] - 5s 314us/sample - loss: 2.3229 - acc: 0.1503 - val_loss: 2.3066 - val_acc: 0.1500\n",
      "Epoch 3/10\n",
      "14400/14438 [============================>.] - ETA: 0s - loss: 2.1900 - acc: 0.2185\n",
      "Epoch 00003: val_acc improved from 0.15000 to 0.20000, saving model to Models/PAM2/best_CNN_dFalse_bnFalse.hdf5\n",
      "14438/14438 [==============================] - 5s 313us/sample - loss: 2.1897 - acc: 0.2187 - val_loss: 2.3332 - val_acc: 0.2000\n",
      "Epoch 4/10\n",
      "14400/14438 [============================>.] - ETA: 0s - loss: 2.0977 - acc: 0.2490\n",
      "Epoch 00004: val_acc improved from 0.20000 to 0.24500, saving model to Models/PAM2/best_CNN_dFalse_bnFalse.hdf5\n",
      "14438/14438 [==============================] - 5s 313us/sample - loss: 2.0974 - acc: 0.2491 - val_loss: 2.2120 - val_acc: 0.2450\n",
      "Epoch 5/10\n",
      "14400/14438 [============================>.] - ETA: 0s - loss: 2.0367 - acc: 0.2778\n",
      "Epoch 00005: val_acc improved from 0.24500 to 0.28000, saving model to Models/PAM2/best_CNN_dFalse_bnFalse.hdf5\n",
      "14438/14438 [==============================] - 5s 313us/sample - loss: 2.0360 - acc: 0.2780 - val_loss: 2.0697 - val_acc: 0.2800\n",
      "Epoch 6/10\n",
      "14400/14438 [============================>.] - ETA: 0s - loss: 2.0116 - acc: 0.2812\n",
      "Epoch 00006: val_acc improved from 0.28000 to 0.30000, saving model to Models/PAM2/best_CNN_dFalse_bnFalse.hdf5\n",
      "14438/14438 [==============================] - 5s 313us/sample - loss: 2.0120 - acc: 0.2809 - val_loss: 2.0568 - val_acc: 0.3000\n",
      "Epoch 7/10\n",
      "14400/14438 [============================>.] - ETA: 0s - loss: 1.9742 - acc: 0.2968\n",
      "Epoch 00007: val_acc did not improve from 0.30000\n",
      "14438/14438 [==============================] - 4s 310us/sample - loss: 1.9743 - acc: 0.2969 - val_loss: 1.9300 - val_acc: 0.2900\n",
      "Epoch 8/10\n",
      "14400/14438 [============================>.] - ETA: 0s - loss: 1.9286 - acc: 0.3099\n",
      "Epoch 00008: val_acc did not improve from 0.30000\n",
      "14438/14438 [==============================] - 4s 310us/sample - loss: 1.9281 - acc: 0.3099 - val_loss: 1.9081 - val_acc: 0.2800\n",
      "Epoch 9/10\n",
      "14400/14438 [============================>.] - ETA: 0s - loss: 1.8837 - acc: 0.3265\n",
      "Epoch 00009: val_acc did not improve from 0.30000\n",
      "14438/14438 [==============================] - 4s 310us/sample - loss: 1.8838 - acc: 0.3265 - val_loss: 1.9600 - val_acc: 0.2650\n",
      "Epoch 10/10\n",
      "14400/14438 [============================>.] - ETA: 0s - loss: 1.8541 - acc: 0.3380\n",
      "Epoch 00010: val_acc did not improve from 0.30000\n",
      "14438/14438 [==============================] - 4s 310us/sample - loss: 1.8539 - acc: 0.3381 - val_loss: 1.9836 - val_acc: 0.2550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vikranth/anaconda3/envs/tensorflow/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reshaping data for different models ...\n",
      "CNN\n",
      "building the model ...\n",
      "Model: \"CNN\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Conv_1 (Conv2D)              (None, 27, 512, 32)       128       \n",
      "_________________________________________________________________\n",
      "Max_pool_1 (MaxPooling2D)    (None, 27, 256, 32)       0         \n",
      "_________________________________________________________________\n",
      "Drop_1 (Dropout)             (None, 27, 256, 32)       0         \n",
      "_________________________________________________________________\n",
      "Conv_2 (Conv2D)              (None, 27, 256, 32)       3104      \n",
      "_________________________________________________________________\n",
      "Max_pool_2 (MaxPooling2D)    (None, 27, 128, 32)       0         \n",
      "_________________________________________________________________\n",
      "Drop_2 (Dropout)             (None, 27, 128, 32)       0         \n",
      "_________________________________________________________________\n",
      "Flatten_1 (Flatten)          (None, 110592)            0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 32)                3538976   \n",
      "_________________________________________________________________\n",
      "Drop_3 (Dropout)             (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_out (Dense)            (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 3,542,604\n",
      "Trainable params: 3,542,604\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "model training ...\n",
      "Train on 14438 samples, validate on 200 samples\n",
      "Epoch 1/10\n",
      "14400/14438 [============================>.] - ETA: 0s - loss: 4.3832 - acc: 0.1694\n",
      "Epoch 00001: val_acc improved from -inf to 0.15500, saving model to Models/PAM2/best_CNN_dTrue_bnFalse.hdf5\n",
      "14438/14438 [==============================] - 8s 575us/sample - loss: 4.3778 - acc: 0.1695 - val_loss: 2.3033 - val_acc: 0.1550\n",
      "Epoch 2/10\n",
      "14400/14438 [============================>.] - ETA: 0s - loss: 2.2833 - acc: 0.2008\n",
      "Epoch 00002: val_acc improved from 0.15500 to 0.20500, saving model to Models/PAM2/best_CNN_dTrue_bnFalse.hdf5\n",
      "14438/14438 [==============================] - 6s 443us/sample - loss: 2.2826 - acc: 0.2011 - val_loss: 2.2924 - val_acc: 0.2050\n",
      "Epoch 3/10\n",
      "14400/14438 [============================>.] - ETA: 0s - loss: 2.2687 - acc: 0.2055\n",
      "Epoch 00003: val_acc did not improve from 0.20500\n",
      "14438/14438 [==============================] - 6s 440us/sample - loss: 2.2690 - acc: 0.2054 - val_loss: 2.2821 - val_acc: 0.2050\n",
      "Epoch 4/10\n",
      "14400/14438 [============================>.] - ETA: 0s - loss: 2.2607 - acc: 0.2039\n",
      "Epoch 00004: val_acc did not improve from 0.20500\n",
      "14438/14438 [==============================] - 6s 441us/sample - loss: 2.2603 - acc: 0.2040 - val_loss: 2.2754 - val_acc: 0.2050\n",
      "Epoch 5/10\n",
      "14400/14438 [============================>.] - ETA: 0s - loss: 2.2494 - acc: 0.2046\n",
      "Epoch 00005: val_acc did not improve from 0.20500\n",
      "14438/14438 [==============================] - 6s 441us/sample - loss: 2.2496 - acc: 0.2045 - val_loss: 2.2704 - val_acc: 0.2050\n",
      "Epoch 6/10\n",
      "14400/14438 [============================>.] - ETA: 0s - loss: 2.2429 - acc: 0.2045\n",
      "Epoch 00006: val_acc did not improve from 0.20500\n",
      "14438/14438 [==============================] - 6s 440us/sample - loss: 2.2426 - acc: 0.2047 - val_loss: 2.2581 - val_acc: 0.2050\n",
      "Epoch 7/10\n",
      "14400/14438 [============================>.] - ETA: 0s - loss: 2.2305 - acc: 0.2049\n",
      "Epoch 00007: val_acc did not improve from 0.20500\n",
      "14438/14438 [==============================] - 6s 443us/sample - loss: 2.2303 - acc: 0.2052 - val_loss: 2.2544 - val_acc: 0.2050\n",
      "Epoch 8/10\n",
      "14400/14438 [============================>.] - ETA: 0s - loss: 2.2196 - acc: 0.2074\n",
      "Epoch 00008: val_acc did not improve from 0.20500\n",
      "14438/14438 [==============================] - 6s 445us/sample - loss: 2.2196 - acc: 0.2074 - val_loss: 2.2738 - val_acc: 0.2050\n",
      "Epoch 9/10\n",
      "14400/14438 [============================>.] - ETA: 0s - loss: 2.2073 - acc: 0.2101\n",
      "Epoch 00009: val_acc improved from 0.20500 to 0.21000, saving model to Models/PAM2/best_CNN_dTrue_bnFalse.hdf5\n",
      "14438/14438 [==============================] - 6s 446us/sample - loss: 2.2077 - acc: 0.2099 - val_loss: 2.3544 - val_acc: 0.2100\n",
      "Epoch 10/10\n",
      "14400/14438 [============================>.] - ETA: 0s - loss: 2.1964 - acc: 0.2108\n",
      "Epoch 00010: val_acc improved from 0.21000 to 0.23000, saving model to Models/PAM2/best_CNN_dTrue_bnFalse.hdf5\n",
      "14438/14438 [==============================] - 6s 445us/sample - loss: 2.1966 - acc: 0.2108 - val_loss: 2.3568 - val_acc: 0.2300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vikranth/anaconda3/envs/tensorflow/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reshaping data for different models ...\n",
      "CNN\n",
      "building the model ...\n",
      "Model: \"CNN\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Conv_1 (Conv2D)              (None, 27, 512, 32)       128       \n",
      "_________________________________________________________________\n",
      "Bn_1 (BatchNormalization)    (None, 27, 512, 32)       128       \n",
      "_________________________________________________________________\n",
      "Max_pool_1 (MaxPooling2D)    (None, 27, 256, 32)       0         \n",
      "_________________________________________________________________\n",
      "Conv_2 (Conv2D)              (None, 27, 256, 32)       3104      \n",
      "_________________________________________________________________\n",
      "Bn_2 (BatchNormalization)    (None, 27, 256, 32)       128       \n",
      "_________________________________________________________________\n",
      "Max_pool_2 (MaxPooling2D)    (None, 27, 128, 32)       0         \n",
      "_________________________________________________________________\n",
      "Flatten_1 (Flatten)          (None, 110592)            0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 32)                3538976   \n",
      "_________________________________________________________________\n",
      "Bn_3 (BatchNormalization)    (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dense_out (Dense)            (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 3,542,988\n",
      "Trainable params: 3,542,796\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n",
      "None\n",
      "model training ...\n",
      "Train on 14438 samples, validate on 200 samples\n",
      "Epoch 1/10\n",
      "14400/14438 [============================>.] - ETA: 0s - loss: 0.8882 - acc: 0.7959\n",
      "Epoch 00001: val_acc improved from -inf to 0.16500, saving model to Models/PAM2/best_CNN_dFalse_bnTrue.hdf5\n",
      "14438/14438 [==============================] - 10s 694us/sample - loss: 0.8869 - acc: 0.7964 - val_loss: 3.9419 - val_acc: 0.1650\n",
      "Epoch 2/10\n",
      "14400/14438 [============================>.] - ETA: 0s - loss: 0.2175 - acc: 0.9831\n",
      "Epoch 00002: val_acc improved from 0.16500 to 0.25000, saving model to Models/PAM2/best_CNN_dFalse_bnTrue.hdf5\n",
      "14438/14438 [==============================] - 7s 516us/sample - loss: 0.2174 - acc: 0.9831 - val_loss: 2.5447 - val_acc: 0.2500\n",
      "Epoch 3/10\n",
      "14400/14438 [============================>.] - ETA: 0s - loss: 0.0952 - acc: 0.9955\n",
      "Epoch 00003: val_acc improved from 0.25000 to 0.37000, saving model to Models/PAM2/best_CNN_dFalse_bnTrue.hdf5\n",
      "14438/14438 [==============================] - 7s 517us/sample - loss: 0.0951 - acc: 0.9955 - val_loss: 2.0991 - val_acc: 0.3700\n",
      "Epoch 4/10\n",
      "14400/14438 [============================>.] - ETA: 0s - loss: 0.0436 - acc: 0.9997\n",
      "Epoch 00004: val_acc improved from 0.37000 to 0.59000, saving model to Models/PAM2/best_CNN_dFalse_bnTrue.hdf5\n",
      "14438/14438 [==============================] - 7s 517us/sample - loss: 0.0437 - acc: 0.9997 - val_loss: 1.6750 - val_acc: 0.5900\n",
      "Epoch 5/10\n",
      "14400/14438 [============================>.] - ETA: 0s - loss: 0.0266 - acc: 0.9999\n",
      "Epoch 00005: val_acc improved from 0.59000 to 0.79500, saving model to Models/PAM2/best_CNN_dFalse_bnTrue.hdf5\n",
      "14438/14438 [==============================] - 7s 516us/sample - loss: 0.0266 - acc: 0.9999 - val_loss: 1.0931 - val_acc: 0.7950\n",
      "Epoch 6/10\n",
      "14400/14438 [============================>.] - ETA: 0s - loss: 0.0170 - acc: 1.0000\n",
      "Epoch 00006: val_acc did not improve from 0.79500\n",
      "14438/14438 [==============================] - 7s 511us/sample - loss: 0.0170 - acc: 1.0000 - val_loss: 0.9173 - val_acc: 0.7750\n",
      "Epoch 7/10\n",
      "14400/14438 [============================>.] - ETA: 0s - loss: 0.0118 - acc: 1.0000\n",
      "Epoch 00007: val_acc improved from 0.79500 to 0.80500, saving model to Models/PAM2/best_CNN_dFalse_bnTrue.hdf5\n",
      "14438/14438 [==============================] - 7s 519us/sample - loss: 0.0118 - acc: 1.0000 - val_loss: 0.7063 - val_acc: 0.8050\n",
      "Epoch 8/10\n",
      "14400/14438 [============================>.] - ETA: 0s - loss: 0.0083 - acc: 1.0000\n",
      "Epoch 00008: val_acc improved from 0.80500 to 0.86000, saving model to Models/PAM2/best_CNN_dFalse_bnTrue.hdf5\n",
      "14438/14438 [==============================] - 7s 517us/sample - loss: 0.0083 - acc: 1.0000 - val_loss: 0.4485 - val_acc: 0.8600\n",
      "Epoch 9/10\n",
      "14400/14438 [============================>.] - ETA: 0s - loss: 0.0064 - acc: 1.0000\n",
      "Epoch 00009: val_acc improved from 0.86000 to 0.90000, saving model to Models/PAM2/best_CNN_dFalse_bnTrue.hdf5\n",
      "14438/14438 [==============================] - 7s 518us/sample - loss: 0.0064 - acc: 1.0000 - val_loss: 0.3590 - val_acc: 0.9000\n",
      "Epoch 10/10\n",
      "14400/14438 [============================>.] - ETA: 0s - loss: 0.0051 - acc: 1.0000\n",
      "Epoch 00010: val_acc improved from 0.90000 to 0.92000, saving model to Models/PAM2/best_CNN_dFalse_bnTrue.hdf5\n",
      "14438/14438 [==============================] - 7s 517us/sample - loss: 0.0051 - acc: 1.0000 - val_loss: 0.2662 - val_acc: 0.9200\n",
      "Reshaping data for different models ...\n",
      "CNN\n",
      "building the model ...\n",
      "Model: \"CNN\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Conv_1 (Conv2D)              (None, 27, 512, 32)       128       \n",
      "_________________________________________________________________\n",
      "Bn_1 (BatchNormalization)    (None, 27, 512, 32)       128       \n",
      "_________________________________________________________________\n",
      "Max_pool_1 (MaxPooling2D)    (None, 27, 256, 32)       0         \n",
      "_________________________________________________________________\n",
      "Drop_1 (Dropout)             (None, 27, 256, 32)       0         \n",
      "_________________________________________________________________\n",
      "Conv_2 (Conv2D)              (None, 27, 256, 32)       3104      \n",
      "_________________________________________________________________\n",
      "Bn_2 (BatchNormalization)    (None, 27, 256, 32)       128       \n",
      "_________________________________________________________________\n",
      "Max_pool_2 (MaxPooling2D)    (None, 27, 128, 32)       0         \n",
      "_________________________________________________________________\n",
      "Drop_2 (Dropout)             (None, 27, 128, 32)       0         \n",
      "_________________________________________________________________\n",
      "Flatten_1 (Flatten)          (None, 110592)            0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 32)                3538976   \n",
      "_________________________________________________________________\n",
      "Bn_3 (BatchNormalization)    (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "Drop_3 (Dropout)             (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_out (Dense)            (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 3,542,988\n",
      "Trainable params: 3,542,796\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n",
      "None\n",
      "model training ...\n",
      "Train on 14438 samples, validate on 200 samples\n",
      "Epoch 1/10\n",
      "14400/14438 [============================>.] - ETA: 0s - loss: 0.8350 - acc: 0.7856\n",
      "Epoch 00001: val_acc improved from -inf to 0.59500, saving model to Models/PAM2/best_CNN_dTrue_bnTrue.hdf5\n",
      "14438/14438 [==============================] - 12s 858us/sample - loss: 0.8338 - acc: 0.7861 - val_loss: 1.4247 - val_acc: 0.5950\n",
      "Epoch 2/10\n",
      "14400/14438 [============================>.] - ETA: 0s - loss: 0.2849 - acc: 0.9481\n",
      "Epoch 00002: val_acc improved from 0.59500 to 0.64500, saving model to Models/PAM2/best_CNN_dTrue_bnTrue.hdf5\n",
      "14438/14438 [==============================] - 9s 650us/sample - loss: 0.2847 - acc: 0.9482 - val_loss: 1.0753 - val_acc: 0.6450\n",
      "Epoch 3/10\n",
      "14400/14438 [============================>.] - ETA: 0s - loss: 0.1398 - acc: 0.9828\n",
      "Epoch 00003: val_acc improved from 0.64500 to 0.67500, saving model to Models/PAM2/best_CNN_dTrue_bnTrue.hdf5\n",
      "14438/14438 [==============================] - 9s 650us/sample - loss: 0.1398 - acc: 0.9828 - val_loss: 0.9490 - val_acc: 0.6750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10\n",
      "14400/14438 [============================>.] - ETA: 0s - loss: 0.0875 - acc: 0.9907\n",
      "Epoch 00004: val_acc did not improve from 0.67500\n",
      "14438/14438 [==============================] - 9s 644us/sample - loss: 0.0878 - acc: 0.9906 - val_loss: 0.9954 - val_acc: 0.6750\n",
      "Epoch 5/10\n",
      "14400/14438 [============================>.] - ETA: 0s - loss: 0.0619 - acc: 0.9939\n",
      "Epoch 00005: val_acc improved from 0.67500 to 0.69500, saving model to Models/PAM2/best_CNN_dTrue_bnTrue.hdf5\n",
      "14438/14438 [==============================] - 9s 648us/sample - loss: 0.0619 - acc: 0.9939 - val_loss: 0.9942 - val_acc: 0.6950\n",
      "Epoch 6/10\n",
      "14400/14438 [============================>.] - ETA: 0s - loss: 0.0435 - acc: 0.9970\n",
      "Epoch 00006: val_acc improved from 0.69500 to 0.74500, saving model to Models/PAM2/best_CNN_dTrue_bnTrue.hdf5\n",
      "14438/14438 [==============================] - 9s 649us/sample - loss: 0.0435 - acc: 0.9970 - val_loss: 0.8313 - val_acc: 0.7450\n",
      "Epoch 7/10\n",
      "14400/14438 [============================>.] - ETA: 0s - loss: 0.0333 - acc: 0.9977\n",
      "Epoch 00007: val_acc improved from 0.74500 to 0.79000, saving model to Models/PAM2/best_CNN_dTrue_bnTrue.hdf5\n",
      "14438/14438 [==============================] - 9s 652us/sample - loss: 0.0333 - acc: 0.9977 - val_loss: 0.5919 - val_acc: 0.7900\n",
      "Epoch 8/10\n",
      "14400/14438 [============================>.] - ETA: 0s - loss: 0.0260 - acc: 0.9983\n",
      "Epoch 00008: val_acc improved from 0.79000 to 0.81500, saving model to Models/PAM2/best_CNN_dTrue_bnTrue.hdf5\n",
      "14438/14438 [==============================] - 9s 653us/sample - loss: 0.0260 - acc: 0.9983 - val_loss: 0.5298 - val_acc: 0.8150\n",
      "Epoch 9/10\n",
      "14400/14438 [============================>.] - ETA: 0s - loss: 0.0219 - acc: 0.9991\n",
      "Epoch 00009: val_acc improved from 0.81500 to 0.84500, saving model to Models/PAM2/best_CNN_dTrue_bnTrue.hdf5\n",
      "14438/14438 [==============================] - 9s 651us/sample - loss: 0.0220 - acc: 0.9990 - val_loss: 0.4323 - val_acc: 0.8450\n",
      "Epoch 10/10\n",
      "14400/14438 [============================>.] - ETA: 0s - loss: 0.0266 - acc: 0.9976\n",
      "Epoch 00010: val_acc did not improve from 0.84500\n",
      "14438/14438 [==============================] - 9s 646us/sample - loss: 0.0266 - acc: 0.9976 - val_loss: 0.5482 - val_acc: 0.8250\n",
      "Reshaping data for different models ...\n",
      "LSTM\n",
      "building the model ...\n",
      "Model: \"LSTM\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Lstm_1 (LSTM)                (None, 512, 32)           7680      \n",
      "_________________________________________________________________\n",
      "Lstm_2 (LSTM)                (None, 32)                8320      \n",
      "_________________________________________________________________\n",
      "dense_out (Dense)            (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 16,396\n",
      "Trainable params: 16,396\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "model training ...\n",
      "Train on 14438 samples, validate on 200 samples\n",
      "Epoch 1/10\n",
      "14400/14438 [============================>.] - ETA: 0s - loss: 2.0320 - acc: 0.3644\n",
      "Epoch 00001: val_acc improved from -inf to 0.39500, saving model to Models/PAM2/best_LSTM_dFalse_bnFalse.hdf5\n",
      "14438/14438 [==============================] - 63s 4ms/sample - loss: 2.0304 - acc: 0.3650 - val_loss: 1.8764 - val_acc: 0.3950\n",
      "Epoch 2/10\n",
      "14400/14438 [============================>.] - ETA: 0s - loss: 1.2858 - acc: 0.6053\n",
      "Epoch 00002: val_acc improved from 0.39500 to 0.45500, saving model to Models/PAM2/best_LSTM_dFalse_bnFalse.hdf5\n",
      "14438/14438 [==============================] - 57s 4ms/sample - loss: 1.2856 - acc: 0.6053 - val_loss: 1.6978 - val_acc: 0.4550\n",
      "Epoch 3/10\n",
      "14400/14438 [============================>.] - ETA: 0s - loss: 0.9959 - acc: 0.6910\n",
      "Epoch 00003: val_acc improved from 0.45500 to 0.50500, saving model to Models/PAM2/best_LSTM_dFalse_bnFalse.hdf5\n",
      "14438/14438 [==============================] - 57s 4ms/sample - loss: 0.9953 - acc: 0.6914 - val_loss: 1.5352 - val_acc: 0.5050\n",
      "Epoch 4/10\n",
      "14400/14438 [============================>.] - ETA: 0s - loss: 0.9161 - acc: 0.7246\n",
      "Epoch 00004: val_acc improved from 0.50500 to 0.54000, saving model to Models/PAM2/best_LSTM_dFalse_bnFalse.hdf5\n",
      "14438/14438 [==============================] - 57s 4ms/sample - loss: 0.9161 - acc: 0.7245 - val_loss: 1.4988 - val_acc: 0.5400\n",
      "Epoch 5/10\n",
      "14400/14438 [============================>.] - ETA: 0s - loss: 0.8525 - acc: 0.7388\n",
      "Epoch 00005: val_acc improved from 0.54000 to 0.56000, saving model to Models/PAM2/best_LSTM_dFalse_bnFalse.hdf5\n",
      "14438/14438 [==============================] - 57s 4ms/sample - loss: 0.8521 - acc: 0.7390 - val_loss: 1.3653 - val_acc: 0.5600\n",
      "Epoch 6/10\n",
      "14400/14438 [============================>.] - ETA: 0s - loss: 0.7410 - acc: 0.7751\n",
      "Epoch 00006: val_acc improved from 0.56000 to 0.64000, saving model to Models/PAM2/best_LSTM_dFalse_bnFalse.hdf5\n",
      "14438/14438 [==============================] - 57s 4ms/sample - loss: 0.7407 - acc: 0.7752 - val_loss: 1.2239 - val_acc: 0.6400\n",
      "Epoch 7/10\n",
      "14400/14438 [============================>.] - ETA: 0s - loss: 0.9812 - acc: 0.6849\n",
      "Epoch 00007: val_acc did not improve from 0.64000\n",
      "14438/14438 [==============================] - 57s 4ms/sample - loss: 0.9813 - acc: 0.6851 - val_loss: 1.8580 - val_acc: 0.4700\n",
      "Epoch 8/10\n",
      "14400/14438 [============================>.] - ETA: 0s - loss: 1.0368 - acc: 0.6768\n",
      "Epoch 00008: val_acc did not improve from 0.64000\n",
      "14438/14438 [==============================] - 57s 4ms/sample - loss: 1.0363 - acc: 0.6770 - val_loss: 1.5965 - val_acc: 0.4700\n",
      "Epoch 9/10\n",
      "14400/14438 [============================>.] - ETA: 0s - loss: 0.9136 - acc: 0.6940\n",
      "Epoch 00009: val_acc did not improve from 0.64000\n",
      "14438/14438 [==============================] - 57s 4ms/sample - loss: 0.9138 - acc: 0.6942 - val_loss: 1.3658 - val_acc: 0.5600\n",
      "Epoch 10/10\n",
      "14400/14438 [============================>.] - ETA: 0s - loss: 0.8263 - acc: 0.7291\n",
      "Epoch 00010: val_acc did not improve from 0.64000\n",
      "14438/14438 [==============================] - 57s 4ms/sample - loss: 0.8262 - acc: 0.7290 - val_loss: 1.2793 - val_acc: 0.6200\n",
      "WARNING:tensorflow:From /home/vikranth/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:97: calling Orthogonal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "Reshaping data for different models ...\n",
      "LSTM\n",
      "building the model ...\n",
      "Model: \"LSTM\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Lstm_1 (LSTM)                (None, 512, 32)           7680      \n",
      "_________________________________________________________________\n",
      "Drop_1 (Dropout)             (None, 512, 32)           0         \n",
      "_________________________________________________________________\n",
      "Lstm_2 (LSTM)                (None, 32)                8320      \n",
      "_________________________________________________________________\n",
      "Drop_2 (Dropout)             (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_out (Dense)            (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 16,396\n",
      "Trainable params: 16,396\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "model training ...\n",
      "Train on 14438 samples, validate on 200 samples\n",
      "Epoch 1/10\n",
      "14400/14438 [============================>.] - ETA: 0s - loss: 2.0935 - acc: 0.3561\n",
      "Epoch 00001: val_acc improved from -inf to 0.31000, saving model to Models/PAM2/best_LSTM_dTrue_bnFalse.hdf5\n",
      "14438/14438 [==============================] - 63s 4ms/sample - loss: 2.0926 - acc: 0.3565 - val_loss: 1.9725 - val_acc: 0.3100\n",
      "Epoch 2/10\n",
      "14400/14438 [============================>.] - ETA: 0s - loss: 1.3896 - acc: 0.5819\n",
      "Epoch 00002: val_acc improved from 0.31000 to 0.38500, saving model to Models/PAM2/best_LSTM_dTrue_bnFalse.hdf5\n",
      "14438/14438 [==============================] - 57s 4ms/sample - loss: 1.3888 - acc: 0.5823 - val_loss: 1.6658 - val_acc: 0.3850\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10\n",
      "14400/14438 [============================>.] - ETA: 0s - loss: 1.0709 - acc: 0.6722\n",
      "Epoch 00003: val_acc improved from 0.38500 to 0.49500, saving model to Models/PAM2/best_LSTM_dTrue_bnFalse.hdf5\n",
      "14438/14438 [==============================] - 57s 4ms/sample - loss: 1.0703 - acc: 0.6722 - val_loss: 1.5605 - val_acc: 0.4950\n",
      "Epoch 4/10\n",
      "14400/14438 [============================>.] - ETA: 0s - loss: 0.9767 - acc: 0.7010\n",
      "Epoch 00004: val_acc improved from 0.49500 to 0.52500, saving model to Models/PAM2/best_LSTM_dTrue_bnFalse.hdf5\n",
      "14438/14438 [==============================] - 57s 4ms/sample - loss: 0.9770 - acc: 0.7007 - val_loss: 1.5586 - val_acc: 0.5250\n",
      "Epoch 5/10\n",
      "14400/14438 [============================>.] - ETA: 0s - loss: 0.8982 - acc: 0.7266\n",
      "Epoch 00005: val_acc did not improve from 0.52500\n",
      "14438/14438 [==============================] - 57s 4ms/sample - loss: 0.8998 - acc: 0.7263 - val_loss: 1.6175 - val_acc: 0.5050\n",
      "Epoch 6/10\n",
      "14400/14438 [============================>.] - ETA: 0s - loss: 0.9241 - acc: 0.7115\n",
      "Epoch 00006: val_acc did not improve from 0.52500\n",
      "14438/14438 [==============================] - 57s 4ms/sample - loss: 0.9238 - acc: 0.7117 - val_loss: 1.5740 - val_acc: 0.5200\n",
      "Epoch 7/10\n",
      "14400/14438 [============================>.] - ETA: 0s - loss: 0.7917 - acc: 0.7587\n",
      "Epoch 00007: val_acc improved from 0.52500 to 0.53500, saving model to Models/PAM2/best_LSTM_dTrue_bnFalse.hdf5\n",
      "14438/14438 [==============================] - 57s 4ms/sample - loss: 0.7915 - acc: 0.7587 - val_loss: 1.5208 - val_acc: 0.5350\n",
      "Epoch 8/10\n",
      "14400/14438 [============================>.] - ETA: 0s - loss: 0.7604 - acc: 0.7669\n",
      "Epoch 00008: val_acc improved from 0.53500 to 0.55000, saving model to Models/PAM2/best_LSTM_dTrue_bnFalse.hdf5\n",
      "14438/14438 [==============================] - 57s 4ms/sample - loss: 0.7607 - acc: 0.7669 - val_loss: 1.5750 - val_acc: 0.5500\n",
      "Epoch 9/10\n",
      "14400/14438 [============================>.] - ETA: 0s - loss: 1.2363 - acc: 0.6540\n",
      "Epoch 00009: val_acc did not improve from 0.55000\n",
      "14438/14438 [==============================] - 57s 4ms/sample - loss: 1.2358 - acc: 0.6540 - val_loss: 1.6124 - val_acc: 0.5250\n",
      "Epoch 10/10\n",
      "14400/14438 [============================>.] - ETA: 0s - loss: 0.9925 - acc: 0.6967\n",
      "Epoch 00010: val_acc improved from 0.55000 to 0.57500, saving model to Models/PAM2/best_LSTM_dTrue_bnFalse.hdf5\n",
      "14438/14438 [==============================] - 57s 4ms/sample - loss: 0.9925 - acc: 0.6967 - val_loss: 1.4216 - val_acc: 0.5750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vikranth/anaconda3/envs/tensorflow/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reshaping data for different models ...\n",
      "LSTM\n",
      "building the model ...\n",
      "Model: \"LSTM\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Lstm_1 (LSTM)                (None, 512, 32)           7680      \n",
      "_________________________________________________________________\n",
      "Bn_1 (BatchNormalization)    (None, 512, 32)           128       \n",
      "_________________________________________________________________\n",
      "Lstm_2 (LSTM)                (None, 32)                8320      \n",
      "_________________________________________________________________\n",
      "Bn_2 (BatchNormalization)    (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dense_out (Dense)            (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 16,652\n",
      "Trainable params: 16,524\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n",
      "None\n",
      "model training ...\n",
      "Train on 14438 samples, validate on 200 samples\n",
      "Epoch 1/10\n",
      "14400/14438 [============================>.] - ETA: 0s - loss: 1.7636 - acc: 0.4531\n",
      "Epoch 00001: val_acc improved from -inf to 0.40500, saving model to Models/PAM2/best_LSTM_dFalse_bnTrue.hdf5\n",
      "14438/14438 [==============================] - 64s 4ms/sample - loss: 1.7626 - acc: 0.4535 - val_loss: 2.0767 - val_acc: 0.4050\n",
      "Epoch 2/10\n",
      "14400/14438 [============================>.] - ETA: 0s - loss: 1.0730 - acc: 0.6740\n",
      "Epoch 00002: val_acc improved from 0.40500 to 0.47000, saving model to Models/PAM2/best_LSTM_dFalse_bnTrue.hdf5\n",
      "14438/14438 [==============================] - 57s 4ms/sample - loss: 1.0726 - acc: 0.6740 - val_loss: 1.8125 - val_acc: 0.4700\n",
      "Epoch 3/10\n",
      "14400/14438 [============================>.] - ETA: 0s - loss: 0.8265 - acc: 0.7469\n",
      "Epoch 00003: val_acc improved from 0.47000 to 0.52000, saving model to Models/PAM2/best_LSTM_dFalse_bnTrue.hdf5\n",
      "14438/14438 [==============================] - 57s 4ms/sample - loss: 0.8263 - acc: 0.7471 - val_loss: 1.6004 - val_acc: 0.5200\n",
      "Epoch 4/10\n",
      "14400/14438 [============================>.] - ETA: 0s - loss: 0.6897 - acc: 0.7945\n",
      "Epoch 00004: val_acc improved from 0.52000 to 0.59000, saving model to Models/PAM2/best_LSTM_dFalse_bnTrue.hdf5\n",
      "14438/14438 [==============================] - 57s 4ms/sample - loss: 0.6898 - acc: 0.7943 - val_loss: 1.4472 - val_acc: 0.5900\n",
      "Epoch 5/10\n",
      "14400/14438 [============================>.] - ETA: 0s - loss: 0.5886 - acc: 0.8202\n",
      "Epoch 00005: val_acc did not improve from 0.59000\n",
      "14438/14438 [==============================] - 57s 4ms/sample - loss: 0.5880 - acc: 0.8205 - val_loss: 1.4894 - val_acc: 0.5700\n",
      "Epoch 6/10\n",
      "14400/14438 [============================>.] - ETA: 0s - loss: 0.5180 - acc: 0.8422\n",
      "Epoch 00006: val_acc improved from 0.59000 to 0.63500, saving model to Models/PAM2/best_LSTM_dFalse_bnTrue.hdf5\n",
      "14438/14438 [==============================] - 57s 4ms/sample - loss: 0.5175 - acc: 0.8424 - val_loss: 1.3529 - val_acc: 0.6350\n",
      "Epoch 7/10\n",
      "14400/14438 [============================>.] - ETA: 0s - loss: 0.4435 - acc: 0.8642\n",
      "Epoch 00007: val_acc did not improve from 0.63500\n",
      "14438/14438 [==============================] - 57s 4ms/sample - loss: 0.4442 - acc: 0.8640 - val_loss: 1.4455 - val_acc: 0.6350\n",
      "Epoch 8/10\n",
      "14400/14438 [============================>.] - ETA: 0s - loss: 0.4430 - acc: 0.8610\n",
      "Epoch 00008: val_acc did not improve from 0.63500\n",
      "14438/14438 [==============================] - 57s 4ms/sample - loss: 0.4432 - acc: 0.8608 - val_loss: 1.4878 - val_acc: 0.6100\n",
      "Epoch 9/10\n",
      "14400/14438 [============================>.] - ETA: 0s - loss: 0.6011 - acc: 0.8076\n",
      "Epoch 00009: val_acc did not improve from 0.63500\n",
      "14438/14438 [==============================] - 57s 4ms/sample - loss: 0.6008 - acc: 0.8077 - val_loss: 1.5170 - val_acc: 0.5650\n",
      "Epoch 10/10\n",
      "14400/14438 [============================>.] - ETA: 0s - loss: 0.6036 - acc: 0.8085\n",
      "Epoch 00010: val_acc did not improve from 0.63500\n",
      "14438/14438 [==============================] - 57s 4ms/sample - loss: 0.6034 - acc: 0.8086 - val_loss: 1.5914 - val_acc: 0.6000\n",
      "Reshaping data for different models ...\n",
      "LSTM\n",
      "building the model ...\n",
      "Model: \"LSTM\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Lstm_1 (LSTM)                (None, 512, 32)           7680      \n",
      "_________________________________________________________________\n",
      "Bn_1 (BatchNormalization)    (None, 512, 32)           128       \n",
      "_________________________________________________________________\n",
      "Drop_1 (Dropout)             (None, 512, 32)           0         \n",
      "_________________________________________________________________\n",
      "Lstm_2 (LSTM)                (None, 32)                8320      \n",
      "_________________________________________________________________\n",
      "Bn_2 (BatchNormalization)    (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "Drop_2 (Dropout)             (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_out (Dense)            (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 16,652\n",
      "Trainable params: 16,524\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n",
      "None\n",
      "model training ...\n",
      "Train on 14438 samples, validate on 200 samples\n",
      "Epoch 1/10\n",
      "14400/14438 [============================>.] - ETA: 0s - loss: 2.1978 - acc: 0.3139\n",
      "Epoch 00001: val_acc improved from -inf to 0.28000, saving model to Models/PAM2/best_LSTM_dTrue_bnTrue.hdf5\n",
      "14438/14438 [==============================] - 65s 4ms/sample - loss: 2.1960 - acc: 0.3145 - val_loss: 2.1690 - val_acc: 0.2800\n",
      "Epoch 2/10\n",
      "14400/14438 [============================>.] - ETA: 0s - loss: 1.4032 - acc: 0.5644\n",
      "Epoch 00002: val_acc improved from 0.28000 to 0.38000, saving model to Models/PAM2/best_LSTM_dTrue_bnTrue.hdf5\n",
      "14438/14438 [==============================] - 58s 4ms/sample - loss: 1.4028 - acc: 0.5646 - val_loss: 1.8890 - val_acc: 0.3800\n",
      "Epoch 3/10\n",
      "14400/14438 [============================>.] - ETA: 0s - loss: 1.0917 - acc: 0.6557\n",
      "Epoch 00003: val_acc improved from 0.38000 to 0.55000, saving model to Models/PAM2/best_LSTM_dTrue_bnTrue.hdf5\n",
      "14438/14438 [==============================] - 58s 4ms/sample - loss: 1.0921 - acc: 0.6556 - val_loss: 1.5718 - val_acc: 0.5500\n",
      "Epoch 4/10\n",
      "14400/14438 [============================>.] - ETA: 0s - loss: 0.9061 - acc: 0.7249\n",
      "Epoch 00004: val_acc did not improve from 0.55000\n",
      "14438/14438 [==============================] - 57s 4ms/sample - loss: 0.9066 - acc: 0.7248 - val_loss: 1.5220 - val_acc: 0.5300\n",
      "Epoch 5/10\n",
      "14400/14438 [============================>.] - ETA: 0s - loss: 0.7722 - acc: 0.7645\n",
      "Epoch 00005: val_acc improved from 0.55000 to 0.58000, saving model to Models/PAM2/best_LSTM_dTrue_bnTrue.hdf5\n",
      "14438/14438 [==============================] - 58s 4ms/sample - loss: 0.7715 - acc: 0.7649 - val_loss: 1.4078 - val_acc: 0.5800\n",
      "Epoch 6/10\n",
      "14400/14438 [============================>.] - ETA: 0s - loss: 0.6746 - acc: 0.7949\n",
      "Epoch 00006: val_acc did not improve from 0.58000\n",
      "14438/14438 [==============================] - 58s 4ms/sample - loss: 0.6761 - acc: 0.7945 - val_loss: 1.4087 - val_acc: 0.5800\n",
      "Epoch 7/10\n",
      "14400/14438 [============================>.] - ETA: 0s - loss: 0.6615 - acc: 0.8039\n",
      "Epoch 00007: val_acc improved from 0.58000 to 0.65500, saving model to Models/PAM2/best_LSTM_dTrue_bnTrue.hdf5\n",
      "14438/14438 [==============================] - 58s 4ms/sample - loss: 0.6608 - acc: 0.8042 - val_loss: 1.2709 - val_acc: 0.6550\n",
      "Epoch 8/10\n",
      "14400/14438 [============================>.] - ETA: 0s - loss: 0.5634 - acc: 0.8342\n",
      "Epoch 00008: val_acc did not improve from 0.65500\n",
      "14438/14438 [==============================] - 58s 4ms/sample - loss: 0.5632 - acc: 0.8343 - val_loss: 1.3517 - val_acc: 0.6300\n",
      "Epoch 9/10\n",
      "14400/14438 [============================>.] - ETA: 0s - loss: 0.6264 - acc: 0.8138\n",
      "Epoch 00009: val_acc improved from 0.65500 to 0.67000, saving model to Models/PAM2/best_LSTM_dTrue_bnTrue.hdf5\n",
      "14438/14438 [==============================] - 57s 4ms/sample - loss: 0.6268 - acc: 0.8137 - val_loss: 1.0859 - val_acc: 0.6700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10\n",
      "14400/14438 [============================>.] - ETA: 0s - loss: 0.6669 - acc: 0.7907\n",
      "Epoch 00010: val_acc did not improve from 0.67000\n",
      "14438/14438 [==============================] - 57s 4ms/sample - loss: 0.6667 - acc: 0.7908 - val_loss: 1.3138 - val_acc: 0.6500\n",
      "Reshaping data for different models ...\n",
      "ConvLSTM\n",
      "building the model ...\n",
      "Model: \"ConvLSTM\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Conv_1 (Conv2D)              (None, 27, 512, 32)       128       \n",
      "_________________________________________________________________\n",
      "Max_pool_1 (MaxPooling2D)    (None, 27, 256, 32)       0         \n",
      "_________________________________________________________________\n",
      "Conv_2 (Conv2D)              (None, 27, 256, 32)       3104      \n",
      "_________________________________________________________________\n",
      "Max_pool_2 (MaxPooling2D)    (None, 27, 128, 32)       0         \n",
      "_________________________________________________________________\n",
      "Permute_1 (Permute)          (None, 128, 27, 32)       0         \n",
      "_________________________________________________________________\n",
      "Reshape_1 (Reshape)          (None, None, 864)         0         \n",
      "_________________________________________________________________\n",
      "Lstm_1 (LSTM)                (None, 32)                114816    \n",
      "_________________________________________________________________\n",
      "dense_out (Dense)            (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 118,444\n",
      "Trainable params: 118,444\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "model training ...\n",
      "Train on 14438 samples, validate on 200 samples\n",
      "Epoch 1/10\n",
      "14400/14438 [============================>.] - ETA: 0s - loss: 1.6485 - acc: 0.5772\n",
      "Epoch 00001: val_acc improved from -inf to 0.72000, saving model to Models/PAM2/best_ConvLSTM_dFalse_bnFalse.hdf5\n",
      "14438/14438 [==============================] - 16s 1ms/sample - loss: 1.6479 - acc: 0.5774 - val_loss: 1.3730 - val_acc: 0.7200\n",
      "Epoch 2/10\n",
      "14400/14438 [============================>.] - ETA: 0s - loss: 0.9652 - acc: 0.8112\n",
      "Epoch 00002: val_acc improved from 0.72000 to 0.75000, saving model to Models/PAM2/best_ConvLSTM_dFalse_bnFalse.hdf5\n",
      "14438/14438 [==============================] - 12s 798us/sample - loss: 0.9646 - acc: 0.8111 - val_loss: 0.9440 - val_acc: 0.7500\n",
      "Epoch 3/10\n",
      "14400/14438 [============================>.] - ETA: 0s - loss: 0.6839 - acc: 0.8772\n",
      "Epoch 00003: val_acc improved from 0.75000 to 0.76000, saving model to Models/PAM2/best_ConvLSTM_dFalse_bnFalse.hdf5\n",
      "14438/14438 [==============================] - 12s 797us/sample - loss: 0.6835 - acc: 0.8773 - val_loss: 0.8720 - val_acc: 0.7600\n",
      "Epoch 4/10\n",
      "14400/14438 [============================>.] - ETA: 0s - loss: 0.4782 - acc: 0.9195\n",
      "Epoch 00004: val_acc improved from 0.76000 to 0.81500, saving model to Models/PAM2/best_ConvLSTM_dFalse_bnFalse.hdf5\n",
      "14438/14438 [==============================] - 11s 792us/sample - loss: 0.4776 - acc: 0.9197 - val_loss: 0.6904 - val_acc: 0.8150\n",
      "Epoch 5/10\n",
      "14400/14438 [============================>.] - ETA: 0s - loss: 0.3509 - acc: 0.9467\n",
      "Epoch 00005: val_acc improved from 0.81500 to 0.90000, saving model to Models/PAM2/best_ConvLSTM_dFalse_bnFalse.hdf5\n",
      "14438/14438 [==============================] - 12s 797us/sample - loss: 0.3508 - acc: 0.9468 - val_loss: 0.5541 - val_acc: 0.9000\n",
      "Epoch 6/10\n",
      "14400/14438 [============================>.] - ETA: 0s - loss: 0.2674 - acc: 0.9617\n",
      "Epoch 00006: val_acc did not improve from 0.90000\n",
      "14438/14438 [==============================] - 11s 792us/sample - loss: 0.2673 - acc: 0.9616 - val_loss: 0.4872 - val_acc: 0.8850\n",
      "Epoch 7/10\n",
      "14400/14438 [============================>.] - ETA: 0s - loss: 0.2358 - acc: 0.9677\n",
      "Epoch 00007: val_acc did not improve from 0.90000\n",
      "14438/14438 [==============================] - 11s 794us/sample - loss: 0.2358 - acc: 0.9677 - val_loss: 0.4061 - val_acc: 0.9000\n",
      "Epoch 8/10\n",
      "14400/14438 [============================>.] - ETA: 0s - loss: 0.1605 - acc: 0.9806\n",
      "Epoch 00008: val_acc improved from 0.90000 to 0.92500, saving model to Models/PAM2/best_ConvLSTM_dFalse_bnFalse.hdf5\n",
      "14438/14438 [==============================] - 12s 797us/sample - loss: 0.1606 - acc: 0.9805 - val_loss: 0.3436 - val_acc: 0.9250\n",
      "Epoch 9/10\n",
      "14400/14438 [============================>.] - ETA: 0s - loss: 0.1325 - acc: 0.9850\n",
      "Epoch 00009: val_acc improved from 0.92500 to 0.93500, saving model to Models/PAM2/best_ConvLSTM_dFalse_bnFalse.hdf5\n",
      "14438/14438 [==============================] - 12s 798us/sample - loss: 0.1325 - acc: 0.9850 - val_loss: 0.3289 - val_acc: 0.9350\n",
      "Epoch 10/10\n",
      "14400/14438 [============================>.] - ETA: 0s - loss: 0.1097 - acc: 0.9883\n",
      "Epoch 00010: val_acc improved from 0.93500 to 0.94000, saving model to Models/PAM2/best_ConvLSTM_dFalse_bnFalse.hdf5\n",
      "14438/14438 [==============================] - 11s 793us/sample - loss: 0.1096 - acc: 0.9883 - val_loss: 0.2501 - val_acc: 0.9400\n",
      "Reshaping data for different models ...\n",
      "ConvLSTM\n",
      "building the model ...\n",
      "Model: \"ConvLSTM\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Conv_1 (Conv2D)              (None, 27, 512, 32)       128       \n",
      "_________________________________________________________________\n",
      "Max_pool_1 (MaxPooling2D)    (None, 27, 256, 32)       0         \n",
      "_________________________________________________________________\n",
      "Drop_1 (Dropout)             (None, 27, 256, 32)       0         \n",
      "_________________________________________________________________\n",
      "Conv_2 (Conv2D)              (None, 27, 256, 32)       3104      \n",
      "_________________________________________________________________\n",
      "Max_pool_2 (MaxPooling2D)    (None, 27, 128, 32)       0         \n",
      "_________________________________________________________________\n",
      "Drop_2 (Dropout)             (None, 27, 128, 32)       0         \n",
      "_________________________________________________________________\n",
      "Permute_1 (Permute)          (None, 128, 27, 32)       0         \n",
      "_________________________________________________________________\n",
      "Reshape_1 (Reshape)          (None, None, 864)         0         \n",
      "_________________________________________________________________\n",
      "Lstm_1 (LSTM)                (None, 32)                114816    \n",
      "_________________________________________________________________\n",
      "Drop_3 (Dropout)             (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_out (Dense)            (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 118,444\n",
      "Trainable params: 118,444\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "model training ...\n",
      "Train on 14438 samples, validate on 200 samples\n",
      "Epoch 1/10\n",
      "14400/14438 [============================>.] - ETA: 0s - loss: 1.9404 - acc: 0.3916\n",
      "Epoch 00001: val_acc improved from -inf to 0.41500, saving model to Models/PAM2/best_ConvLSTM_dTrue_bnFalse.hdf5\n",
      "14438/14438 [==============================] - 18s 1ms/sample - loss: 1.9386 - acc: 0.3922 - val_loss: 1.6870 - val_acc: 0.4150\n",
      "Epoch 2/10\n",
      "14400/14438 [============================>.] - ETA: 0s - loss: 1.3246 - acc: 0.6162\n",
      "Epoch 00002: val_acc improved from 0.41500 to 0.57500, saving model to Models/PAM2/best_ConvLSTM_dTrue_bnFalse.hdf5\n",
      "14438/14438 [==============================] - 13s 901us/sample - loss: 1.3238 - acc: 0.6164 - val_loss: 1.3573 - val_acc: 0.5750\n",
      "Epoch 3/10\n",
      "14400/14438 [============================>.] - ETA: 0s - loss: 1.0156 - acc: 0.7233\n",
      "Epoch 00003: val_acc improved from 0.57500 to 0.64000, saving model to Models/PAM2/best_ConvLSTM_dTrue_bnFalse.hdf5\n",
      "14438/14438 [==============================] - 13s 897us/sample - loss: 1.0156 - acc: 0.7232 - val_loss: 1.0532 - val_acc: 0.6400\n",
      "Epoch 4/10\n",
      "14400/14438 [============================>.] - ETA: 0s - loss: 0.8278 - acc: 0.7795\n",
      "Epoch 00004: val_acc improved from 0.64000 to 0.67000, saving model to Models/PAM2/best_ConvLSTM_dTrue_bnFalse.hdf5\n",
      "14438/14438 [==============================] - 13s 899us/sample - loss: 0.8276 - acc: 0.7795 - val_loss: 0.8870 - val_acc: 0.6700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10\n",
      "14400/14438 [============================>.] - ETA: 0s - loss: 0.6704 - acc: 0.8304\n",
      "Epoch 00005: val_acc improved from 0.67000 to 0.76000, saving model to Models/PAM2/best_ConvLSTM_dTrue_bnFalse.hdf5\n",
      "14438/14438 [==============================] - 13s 902us/sample - loss: 0.6703 - acc: 0.8304 - val_loss: 0.7557 - val_acc: 0.7600\n",
      "Epoch 6/10\n",
      "14400/14438 [============================>.] - ETA: 0s - loss: 0.5612 - acc: 0.8585\n",
      "Epoch 00006: val_acc improved from 0.76000 to 0.80500, saving model to Models/PAM2/best_ConvLSTM_dTrue_bnFalse.hdf5\n",
      "14438/14438 [==============================] - 13s 904us/sample - loss: 0.5613 - acc: 0.8585 - val_loss: 0.6969 - val_acc: 0.8050\n",
      "Epoch 7/10\n",
      "14400/14438 [============================>.] - ETA: 0s - loss: 0.4582 - acc: 0.8913\n",
      "Epoch 00007: val_acc improved from 0.80500 to 0.81000, saving model to Models/PAM2/best_ConvLSTM_dTrue_bnFalse.hdf5\n",
      "14438/14438 [==============================] - 13s 899us/sample - loss: 0.4582 - acc: 0.8912 - val_loss: 0.6387 - val_acc: 0.8100\n",
      "Epoch 8/10\n",
      "14400/14438 [============================>.] - ETA: 0s - loss: 0.4074 - acc: 0.9008\n",
      "Epoch 00008: val_acc improved from 0.81000 to 0.87500, saving model to Models/PAM2/best_ConvLSTM_dTrue_bnFalse.hdf5\n",
      "14438/14438 [==============================] - 13s 896us/sample - loss: 0.4068 - acc: 0.9010 - val_loss: 0.5560 - val_acc: 0.8750\n",
      "Epoch 9/10\n",
      "14400/14438 [============================>.] - ETA: 0s - loss: 0.3192 - acc: 0.9301\n",
      "Epoch 00009: val_acc did not improve from 0.87500\n",
      "14438/14438 [==============================] - 13s 897us/sample - loss: 0.3194 - acc: 0.9300 - val_loss: 0.4986 - val_acc: 0.8700\n",
      "Epoch 10/10\n",
      "14400/14438 [============================>.] - ETA: 0s - loss: 0.2691 - acc: 0.9422\n",
      "Epoch 00010: val_acc improved from 0.87500 to 0.89500, saving model to Models/PAM2/best_ConvLSTM_dTrue_bnFalse.hdf5\n",
      "14438/14438 [==============================] - 13s 891us/sample - loss: 0.2693 - acc: 0.9422 - val_loss: 0.3640 - val_acc: 0.8950\n",
      "Reshaping data for different models ...\n",
      "ConvLSTM\n",
      "building the model ...\n",
      "Model: \"ConvLSTM\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Conv_1 (Conv2D)              (None, 27, 512, 32)       128       \n",
      "_________________________________________________________________\n",
      "Bn_1 (BatchNormalization)    (None, 27, 512, 32)       128       \n",
      "_________________________________________________________________\n",
      "Max_pool_1 (MaxPooling2D)    (None, 27, 256, 32)       0         \n",
      "_________________________________________________________________\n",
      "Conv_2 (Conv2D)              (None, 27, 256, 32)       3104      \n",
      "_________________________________________________________________\n",
      "Bn_2 (BatchNormalization)    (None, 27, 256, 32)       128       \n",
      "_________________________________________________________________\n",
      "Max_pool_2 (MaxPooling2D)    (None, 27, 128, 32)       0         \n",
      "_________________________________________________________________\n",
      "Permute_1 (Permute)          (None, 128, 27, 32)       0         \n",
      "_________________________________________________________________\n",
      "Reshape_1 (Reshape)          (None, None, 864)         0         \n",
      "_________________________________________________________________\n",
      "Lstm_1 (LSTM)                (None, 32)                114816    \n",
      "_________________________________________________________________\n",
      "dense_out (Dense)            (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 118,700\n",
      "Trainable params: 118,572\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n",
      "None\n",
      "model training ...\n",
      "Train on 14438 samples, validate on 200 samples\n",
      "Epoch 1/10\n",
      "14400/14438 [============================>.] - ETA: 0s - loss: 1.1831 - acc: 0.6881\n",
      "Epoch 00001: val_acc improved from -inf to 0.35500, saving model to Models/PAM2/best_ConvLSTM_dFalse_bnTrue.hdf5\n",
      "14438/14438 [==============================] - 20s 1ms/sample - loss: 1.1818 - acc: 0.6885 - val_loss: 2.0154 - val_acc: 0.3550\n",
      "Epoch 2/10\n",
      "14400/14438 [============================>.] - ETA: 0s - loss: 0.4543 - acc: 0.9111\n",
      "Epoch 00002: val_acc improved from 0.35500 to 0.63500, saving model to Models/PAM2/best_ConvLSTM_dFalse_bnTrue.hdf5\n",
      "14438/14438 [==============================] - 14s 981us/sample - loss: 0.4537 - acc: 0.9113 - val_loss: 1.0832 - val_acc: 0.6350\n",
      "Epoch 3/10\n",
      "14400/14438 [============================>.] - ETA: 0s - loss: 0.2223 - acc: 0.9684\n",
      "Epoch 00003: val_acc improved from 0.63500 to 0.75500, saving model to Models/PAM2/best_ConvLSTM_dFalse_bnTrue.hdf5\n",
      "14438/14438 [==============================] - 14s 981us/sample - loss: 0.2222 - acc: 0.9684 - val_loss: 0.7693 - val_acc: 0.7550\n",
      "Epoch 4/10\n",
      "14400/14438 [============================>.] - ETA: 0s - loss: 0.1351 - acc: 0.9819\n",
      "Epoch 00004: val_acc improved from 0.75500 to 0.86500, saving model to Models/PAM2/best_ConvLSTM_dFalse_bnTrue.hdf5\n",
      "14438/14438 [==============================] - 14s 983us/sample - loss: 0.1350 - acc: 0.9819 - val_loss: 0.4062 - val_acc: 0.8650\n",
      "Epoch 5/10\n",
      "14400/14438 [============================>.] - ETA: 0s - loss: 0.0749 - acc: 0.9924\n",
      "Epoch 00005: val_acc improved from 0.86500 to 0.93000, saving model to Models/PAM2/best_ConvLSTM_dFalse_bnTrue.hdf5\n",
      "14438/14438 [==============================] - 14s 982us/sample - loss: 0.0748 - acc: 0.9924 - val_loss: 0.2314 - val_acc: 0.9300\n",
      "Epoch 6/10\n",
      "14400/14438 [============================>.] - ETA: 0s - loss: 0.0637 - acc: 0.9931\n",
      "Epoch 00006: val_acc improved from 0.93000 to 0.93500, saving model to Models/PAM2/best_ConvLSTM_dFalse_bnTrue.hdf5\n",
      "14438/14438 [==============================] - 14s 984us/sample - loss: 0.0638 - acc: 0.9931 - val_loss: 0.2692 - val_acc: 0.9350\n",
      "Epoch 7/10\n",
      "14400/14438 [============================>.] - ETA: 0s - loss: 0.0453 - acc: 0.9957\n",
      "Epoch 00007: val_acc improved from 0.93500 to 0.95000, saving model to Models/PAM2/best_ConvLSTM_dFalse_bnTrue.hdf5\n",
      "14438/14438 [==============================] - 14s 988us/sample - loss: 0.0455 - acc: 0.9956 - val_loss: 0.1881 - val_acc: 0.9500\n",
      "Epoch 8/10\n",
      "14400/14438 [============================>.] - ETA: 0s - loss: 0.0375 - acc: 0.9972\n",
      "Epoch 00008: val_acc improved from 0.95000 to 0.98000, saving model to Models/PAM2/best_ConvLSTM_dFalse_bnTrue.hdf5\n",
      "14438/14438 [==============================] - 14s 979us/sample - loss: 0.0375 - acc: 0.9972 - val_loss: 0.1164 - val_acc: 0.9800\n",
      "Epoch 9/10\n",
      "14400/14438 [============================>.] - ETA: 0s - loss: 0.0268 - acc: 0.9976\n",
      "Epoch 00009: val_acc did not improve from 0.98000\n",
      "14438/14438 [==============================] - 14s 982us/sample - loss: 0.0268 - acc: 0.9976 - val_loss: 0.1021 - val_acc: 0.9650\n",
      "Epoch 10/10\n",
      "14400/14438 [============================>.] - ETA: 0s - loss: 0.0181 - acc: 0.9992\n",
      "Epoch 00010: val_acc did not improve from 0.98000\n",
      "14438/14438 [==============================] - 14s 982us/sample - loss: 0.0181 - acc: 0.9992 - val_loss: 0.1300 - val_acc: 0.9650\n",
      "Reshaping data for different models ...\n",
      "ConvLSTM\n",
      "building the model ...\n",
      "Model: \"ConvLSTM\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Conv_1 (Conv2D)              (None, 27, 512, 32)       128       \n",
      "_________________________________________________________________\n",
      "Bn_1 (BatchNormalization)    (None, 27, 512, 32)       128       \n",
      "_________________________________________________________________\n",
      "Max_pool_1 (MaxPooling2D)    (None, 27, 256, 32)       0         \n",
      "_________________________________________________________________\n",
      "Drop_1 (Dropout)             (None, 27, 256, 32)       0         \n",
      "_________________________________________________________________\n",
      "Conv_2 (Conv2D)              (None, 27, 256, 32)       3104      \n",
      "_________________________________________________________________\n",
      "Bn_2 (BatchNormalization)    (None, 27, 256, 32)       128       \n",
      "_________________________________________________________________\n",
      "Max_pool_2 (MaxPooling2D)    (None, 27, 128, 32)       0         \n",
      "_________________________________________________________________\n",
      "Drop_2 (Dropout)             (None, 27, 128, 32)       0         \n",
      "_________________________________________________________________\n",
      "Permute_1 (Permute)          (None, 128, 27, 32)       0         \n",
      "_________________________________________________________________\n",
      "Reshape_1 (Reshape)          (None, None, 864)         0         \n",
      "_________________________________________________________________\n",
      "Lstm_1 (LSTM)                (None, 32)                114816    \n",
      "_________________________________________________________________\n",
      "Drop_3 (Dropout)             (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_out (Dense)            (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 118,700\n",
      "Trainable params: 118,572\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n",
      "None\n",
      "model training ...\n",
      "Train on 14438 samples, validate on 200 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "14400/14438 [============================>.] - ETA: 0s - loss: 1.3076 - acc: 0.6027\n",
      "Epoch 00001: val_acc improved from -inf to 0.47000, saving model to Models/PAM2/best_ConvLSTM_dTrue_bnTrue.hdf5\n",
      "14438/14438 [==============================] - 22s 2ms/sample - loss: 1.3064 - acc: 0.6031 - val_loss: 1.5913 - val_acc: 0.4700\n",
      "Epoch 2/10\n",
      "14400/14438 [============================>.] - ETA: 0s - loss: 0.5472 - acc: 0.8558\n",
      "Epoch 00002: val_acc improved from 0.47000 to 0.72000, saving model to Models/PAM2/best_ConvLSTM_dTrue_bnTrue.hdf5\n",
      "14438/14438 [==============================] - 16s 1ms/sample - loss: 0.5467 - acc: 0.8559 - val_loss: 0.9200 - val_acc: 0.7200\n",
      "Epoch 3/10\n",
      "14400/14438 [============================>.] - ETA: 0s - loss: 0.3251 - acc: 0.9235\n",
      "Epoch 00003: val_acc improved from 0.72000 to 0.79500, saving model to Models/PAM2/best_ConvLSTM_dTrue_bnTrue.hdf5\n",
      "14438/14438 [==============================] - 16s 1ms/sample - loss: 0.3249 - acc: 0.9235 - val_loss: 0.5715 - val_acc: 0.7950\n",
      "Epoch 4/10\n",
      "14400/14438 [============================>.] - ETA: 0s - loss: 0.2006 - acc: 0.9590\n",
      "Epoch 00004: val_acc improved from 0.79500 to 0.83500, saving model to Models/PAM2/best_ConvLSTM_dTrue_bnTrue.hdf5\n",
      "14438/14438 [==============================] - 16s 1ms/sample - loss: 0.2003 - acc: 0.9591 - val_loss: 0.5170 - val_acc: 0.8350\n",
      "Epoch 5/10\n",
      "14400/14438 [============================>.] - ETA: 0s - loss: 0.1329 - acc: 0.9772\n",
      "Epoch 00005: val_acc improved from 0.83500 to 0.87500, saving model to Models/PAM2/best_ConvLSTM_dTrue_bnTrue.hdf5\n",
      "14438/14438 [==============================] - 16s 1ms/sample - loss: 0.1329 - acc: 0.9771 - val_loss: 0.4174 - val_acc: 0.8750\n",
      "Epoch 6/10\n",
      "14400/14438 [============================>.] - ETA: 0s - loss: 0.1106 - acc: 0.9797\n",
      "Epoch 00006: val_acc did not improve from 0.87500\n",
      "14438/14438 [==============================] - 16s 1ms/sample - loss: 0.1105 - acc: 0.9798 - val_loss: 0.5528 - val_acc: 0.8600\n",
      "Epoch 7/10\n",
      "14400/14438 [============================>.] - ETA: 0s - loss: 0.0774 - acc: 0.9865\n",
      "Epoch 00007: val_acc improved from 0.87500 to 0.91000, saving model to Models/PAM2/best_ConvLSTM_dTrue_bnTrue.hdf5\n",
      "14438/14438 [==============================] - 16s 1ms/sample - loss: 0.0773 - acc: 0.9865 - val_loss: 0.3498 - val_acc: 0.9100\n",
      "Epoch 8/10\n",
      "14400/14438 [============================>.] - ETA: 0s - loss: 0.0653 - acc: 0.9899\n",
      "Epoch 00008: val_acc improved from 0.91000 to 0.92500, saving model to Models/PAM2/best_ConvLSTM_dTrue_bnTrue.hdf5\n",
      "14438/14438 [==============================] - 16s 1ms/sample - loss: 0.0653 - acc: 0.9900 - val_loss: 0.3240 - val_acc: 0.9250\n",
      "Epoch 9/10\n",
      "14400/14438 [============================>.] - ETA: 0s - loss: 0.0476 - acc: 0.9936\n",
      "Epoch 00009: val_acc improved from 0.92500 to 0.93000, saving model to Models/PAM2/best_ConvLSTM_dTrue_bnTrue.hdf5\n",
      "14438/14438 [==============================] - 16s 1ms/sample - loss: 0.0478 - acc: 0.9935 - val_loss: 0.2552 - val_acc: 0.9300\n",
      "Epoch 10/10\n",
      "14400/14438 [============================>.] - ETA: 0s - loss: 0.0565 - acc: 0.9906\n",
      "Epoch 00010: val_acc did not improve from 0.93000\n",
      "14438/14438 [==============================] - 16s 1ms/sample - loss: 0.0564 - acc: 0.9906 - val_loss: 0.4995 - val_acc: 0.8500\n"
     ]
    }
   ],
   "source": [
    "network_types = ['MLP', 'CNN', 'LSTM', 'ConvLSTM']\n",
    "b_list = [False, True]\n",
    "d_list = [False, True]\n",
    "results = []\n",
    "\n",
    "for network_type in network_types:\n",
    "    for b in b_list:\n",
    "        for d in d_list:\n",
    "            print('Reshaping data for different models ...')\n",
    "            X_train, X_val, X_test = reshape_data(X_train0, X_val0, X_test0, network_type)\n",
    "\n",
    "            #specifying hyper-parameters\n",
    "            batch_size = 300\n",
    "            _, win_len, dim = X_train0.shape\n",
    "\n",
    "            print('building the model ...')\n",
    "            if network_type =='CNN' :\n",
    "                model = model_CNN(dim, win_len, num_classes, num_feat_map=32, p=0.3, batchnorm=b, dropout=d)\n",
    "\n",
    "            if network_type =='ConvLSTM':\n",
    "                model = model_ConvLSTM(dim, win_len, num_classes, num_feat_map=32, p=0.3, batchnorm=b, dropout=d)\n",
    "\n",
    "            if network_type =='LSTM':\n",
    "                model = model_LSTM(dim, win_len, num_classes, num_hidden_lstm=32, p=0.3, batchnorm=b, dropout=d)\n",
    "\n",
    "            if network_type =='MLP': \n",
    "                model = model_MLP(dim, win_len, num_classes, num_hidden_mlp=256, p=0.3, batchnorm=b, dropout=d)\n",
    "\n",
    "            print(model.summary())\n",
    "\n",
    "            print('model training ...')\n",
    "            epochs = 10\n",
    "            model.compile(loss=tensorflow.keras.losses.categorical_crossentropy,\n",
    "                          optimizer='adam',\n",
    "                          metrics=['accuracy'])\n",
    "\n",
    "            model_dir = 'Models/{}'.format(d_name)\n",
    "\n",
    "            name = '{}_d{}_bn{}'.format(network_type, d, b)\n",
    "            tensorboard = TensorBoard(log_dir = 'logs/{}'.format(name))\n",
    "\n",
    "            if not os.path.exists(model_dir):\n",
    "                os.makedirs(model_dir)\n",
    "\n",
    "            # checkpoint\n",
    "            filepath= \"best_{}.hdf5\".format(name)\n",
    "            chk_path = os.path.join(model_dir, filepath)\n",
    "            checkpoint = ModelCheckpoint(chk_path, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "            model.fit(X_train, y_train_binary,\n",
    "                      batch_size=batch_size,\n",
    "                      epochs=epochs,\n",
    "                      verbose=1,\n",
    "                      shuffle=True,\n",
    "                      validation_data=(X_val, y_val_binary),\n",
    "                      callbacks=[tensorboard, checkpoint])\n",
    "\n",
    "            model.save(os.path.join(model_dir,'final_{}.hdf5'.format(name)))\n",
    "            \n",
    "            model = load_model(chk_path)\n",
    "\n",
    "            y_pred = np.argmax(model.predict(X_test), axis=1)\n",
    "            y_true = np.argmax(y_test_binary, axis=1)\n",
    "            cf_matrix = confusion_matrix(y_true, y_pred)\n",
    "            class_wise_f1 = f1_score(y_true, y_pred, average=None)\n",
    "            accuracy = accuracy_score(y_true, y_pred)\n",
    "            results.append((network_type, b, d, cf_matrix, np.mean(class_wise_f1), accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('MLP',\n",
       "  False,\n",
       "  False,\n",
       "  array([[198,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  2, 189,  26,   1,   0,   0,   4,   0,   0,   0,   0,   0],\n",
       "         [  0,  23, 140,   5,   0,   0,   3,   0,   3,   0,   6,   0],\n",
       "         [  0,   0,   2, 249,   0,   0,  10,   0,   8,   0,   0,   0],\n",
       "         [  0,   7,   0,   0,  92,   0,  88,   6,   0,   0,   0,  10],\n",
       "         [  0,   2,   0,   0,   0, 173,   7,   0,   4,   0,   0,  15],\n",
       "         [  0,  16,   0,   2,   0,   0, 200,   0,   1,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   2,  75,   1,   1,   0,   0],\n",
       "         [  0,   0,   0,   1,   0,   0,   2,   1,  68,   0,   2,   0],\n",
       "         [  0,   6,   0,   1,   1,  43,  14,   0,  16, 114,   5,   1],\n",
       "         [  0,  56,  16,   0,   0,   0,  10,   0,   1,  20, 182,   0],\n",
       "         [  0,   0,   0,   0,  38,   0,   0,  11,   0,   0,   0,   0]]),\n",
       "  0.7175698559709597,\n",
       "  0.7706422018348624),\n",
       " ('MLP',\n",
       "  False,\n",
       "  True,\n",
       "  array([[198,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  4, 188,   0,   1,   0,   0,   4,   0,   0,   0,  25,   0],\n",
       "         [  0,  17,  60,   0,   0,   0,   0,   0,   0,   0, 103,   0],\n",
       "         [  0,   1,   0,   0,   0,   0,   0,   0,   0,   0, 268,   0],\n",
       "         [  0,   2,   0,   0,  77,   1,   0,   0,   0,   1, 122,   0],\n",
       "         [  0,   0,   0,   0,   0, 142,   0,   0,   0,   0,  59,   0],\n",
       "         [  0,   5,   0,   0,   0,   0,   1,   0,   0,   0, 213,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  79,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  74,   0],\n",
       "         [  0,   0,   0,   0,   0,  21,   0,   0,   0,  57, 123,   0],\n",
       "         [  0,  21,   0,   0,   0,   0,   1,   0,   0,   1, 262,   0],\n",
       "         [  0,   0,   0,   0,  29,   0,   3,   0,   0,   0,  17,   0]]),\n",
       "  0.36331094443636536,\n",
       "  0.4518348623853211),\n",
       " ('MLP',\n",
       "  True,\n",
       "  False,\n",
       "  array([[198,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0, 222,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,  11,  88,  64,   0,   0,   5,   0,   1,   1,  10,   0],\n",
       "         [  0,   0,   0, 256,   0,   0,  13,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,  13,   0, 190,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0, 193,   1,   6,   1,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0, 219,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,  79,   0,   0,   0,   0],\n",
       "         [  0,   0,   2,   1,   0,   0,   0,   1,  67,   3,   0,   0],\n",
       "         [  0,   0,   1,   0,   0,  43,  27,   2,   5, 121,   2,   0],\n",
       "         [  0,  10,  10,   0,   0,   0,   3,   0,   0,   9, 253,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,  40,   0,   9,   0,   0]]),\n",
       "  0.6993155117465539,\n",
       "  0.7839449541284403),\n",
       " ('MLP',\n",
       "  True,\n",
       "  True,\n",
       "  array([[198,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0, 222,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,  17, 153,   0,   0,   0,   0,   2,   0,   0,   8,   0],\n",
       "         [  0,   0,   0, 255,   0,   0,  14,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,  76,   0, 127,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0, 191,   8,   2,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0, 219,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,  79,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   2,   1,  70,   1,   0,   0],\n",
       "         [  0,  10,   5,   0,   0,  30,   4,   1,   9, 138,   4,   0],\n",
       "         [  0,  28,  13,   0,   0,   0,   0,   1,   0,  20, 223,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,  49,   0,   0,   0,   0]]),\n",
       "  0.7667666352473592,\n",
       "  0.8366972477064221),\n",
       " ('CNN',\n",
       "  False,\n",
       "  False,\n",
       "  array([[198,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [ 25, 103,   0,   5,   0,   0,   0,   0,   0,   0,  89,   0],\n",
       "         [  1,  11,   0,   0,   0,   0,   0,   0,   0,   0, 168,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 269,   0],\n",
       "         [  0,   0,   0,   0, 130,   0,   0,   0,   0,   0,  73,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 201,   0],\n",
       "         [  0,   2,   0,   0,   0,   0,   0,   0,   0,   0, 217,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  79,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  74,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 201,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 285,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  49,   0]]),\n",
       "  0.2179224185665433,\n",
       "  0.3284403669724771),\n",
       " ('CNN',\n",
       "  False,\n",
       "  True,\n",
       "  array([[198,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0, 201,   0,   0,   0,   0,   0,  21,   0,   0],\n",
       "         [  0,   0,   0, 180,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0, 269,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0, 203,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0, 201,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0, 219,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,  79,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,  74,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0, 171,   0,   0,   0,   0,   0,  30,   0,   0],\n",
       "         [  0,   0,   0, 285,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,  49,   0,   0,   0,   0,   0,   0,   0,   0]]),\n",
       "  0.12355339105339107,\n",
       "  0.2279816513761468),\n",
       " ('CNN',\n",
       "  True,\n",
       "  False,\n",
       "  array([[198,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0, 145,  44,   0,   0,   0,   0,   0,   0,   0,  33,   0],\n",
       "         [  0,   0, 152,   0,   0,   0,   0,   0,   0,   3,  25,   0],\n",
       "         [  0,   0,   0, 269,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0, 201,   0,   1,   0,   1,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0, 193,   0,   0,   7,   0,   1,   0],\n",
       "         [  0,   0,   0,   0,   0,   0, 219,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,  79,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,  73,   0,   1,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0, 147,  54,   0],\n",
       "         [  0,   0,   3,   0,   0,   0,   0,   0,   0,   0, 282,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   1,   0,   0,   0,  48]]),\n",
       "  0.9296588461068035,\n",
       "  0.9201834862385321),\n",
       " ('CNN',\n",
       "  True,\n",
       "  True,\n",
       "  array([[198,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0, 200,   0,  22,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,  10, 132,  11,   0,   0,   0,   0,   0,  19,   8,   0],\n",
       "         [  0,   0,   0, 269,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0, 165,   0,  10,   0,  28,   0,   0,   0],\n",
       "         [  0,   7,   0,   6,   0, 181,   0,   0,   2,   5,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0, 219,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,  46,   0,   0,   0,  33,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   8,   0,   0,   0,   0,  66,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0, 198,   3,   0],\n",
       "         [  0,   8,   4,   0,   0,   0,   0,   0,   0,  57, 216,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  49]]),\n",
       "  0.8699567087112748,\n",
       "  0.8834862385321101),\n",
       " ('LSTM',\n",
       "  False,\n",
       "  False,\n",
       "  array([[198,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [ 10,  58,   8,   0,  12,   0,   0,   0,   0,   0, 134,   0],\n",
       "         [  0,   9,  80,  45,   0,   0,   1,   0,   4,   3,  38,   0],\n",
       "         [  0,   0,   0, 199,   0,   0,  40,   2,   8,  20,   0,   0],\n",
       "         [  0,   0,   0,   0, 140,  14,  42,   4,   3,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   8, 183,   0,   0,   1,   7,   2,   0],\n",
       "         [  0,   2,   0,   0,   7,   1, 196,   3,   0,  10,   0,   0],\n",
       "         [  0,   0,   0,  26,   0,   1,   7,  11,   4,  27,   3,   0],\n",
       "         [  0,   7,   9,   7,   5,   0,   6,  14,  12,   6,   5,   3],\n",
       "         [  0,   0,   3,   7,   9,  65,   5,   8,   2,  91,  11,   0],\n",
       "         [  0,   6,  26,  13,   7,   2,  14,   7,   0,   8, 202,   0],\n",
       "         [  0,   2,   1,   0,  45,   0,   0,   0,   1,   0,   0,   0]]),\n",
       "  0.5182057877057359,\n",
       "  0.6284403669724771),\n",
       " ('LSTM',\n",
       "  False,\n",
       "  True,\n",
       "  array([[198,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,  86,  12,   1,   1,   0,   0,   3,   0,   6, 113,   0],\n",
       "         [  0,  25,  66,   3,   0,   6,   2,   1,   0,  20,  57,   0],\n",
       "         [  0,   0,   9, 165,   0,  58,  24,  11,   0,   2,   0,   0],\n",
       "         [  0,   0,   7,   1,  66,  25,  94,   0,   0,  10,   0,   0],\n",
       "         [  0,   0,   0,   0,   0, 188,   0,   0,   0,  10,   3,   0],\n",
       "         [  0,   0,   0,   1,   3,   3, 192,   0,   0,  20,   0,   0],\n",
       "         [  0,   0,   2,  19,   0,   2,   5,  23,   0,  28,   0,   0],\n",
       "         [  1,   0,   3,   9,   7,   9,  12,   5,   0,  25,   3,   0],\n",
       "         [  0,   5,   1,  19,   0,  24,  14,   1,   1, 127,   9,   0],\n",
       "         [  0,  56,   1,   2,   3,   2,  10,   0,   0,   7, 204,   0],\n",
       "         [  0,   0,   0,   0,  31,   0,  18,   0,   0,   0,   0,   0]]),\n",
       "  0.4926723105164976,\n",
       "  0.6032110091743119),\n",
       " ('LSTM',\n",
       "  True,\n",
       "  False,\n",
       "  array([[198,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0, 151,   5,   4,  21,   0,   5,   0,   0,   0,  36,   0],\n",
       "         [  0,  18,  72,  28,   0,   0,  19,  12,   5,  10,  16,   0],\n",
       "         [  0,   0,   0, 241,   1,   0,  16,   6,   3,   1,   0,   1],\n",
       "         [  0,  11,   2,  32,  40,   6,  75,   8,   2,   5,  17,   5],\n",
       "         [  0,   1,   0,   1,   0, 158,   8,   1,   2,   3,  27,   0],\n",
       "         [  0,   1,   0,   6,   7,   0, 190,   1,   2,  10,   2,   0],\n",
       "         [  0,   0,   5,  21,   1,   2,   8,  33,   1,   6,   2,   0],\n",
       "         [  2,   0,   6,   4,   3,   2,   9,  21,   4,  14,   7,   2],\n",
       "         [  0,   5,   4,   7,   2,  63,   7,  16,   1,  89,   6,   1],\n",
       "         [  0,   8,   8,  16,  14,   3,  26,   1,   3,   0, 206,   0],\n",
       "         [  0,   0,   0,   0,  10,   0,  28,   9,   0,   2,   0,   0]]),\n",
       "  0.5208288758517204,\n",
       "  0.6339449541284403),\n",
       " ('LSTM',\n",
       "  True,\n",
       "  True,\n",
       "  array([[198,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  1, 209,   5,   1,   0,   0,   0,   0,   0,   0,   6,   0],\n",
       "         [  0,  22, 135,   0,   0,   0,   3,   0,   1,   5,  14,   0],\n",
       "         [  1,   0,   4, 194,   0,   0,  52,  14,   1,   2,   0,   1],\n",
       "         [  0,   4,   1,  29,  99,   0,  38,  27,   1,   1,   0,   3],\n",
       "         [  0,   5,   0,   6,   1, 150,  24,   2,   6,   3,   4,   0],\n",
       "         [  0,   5,   0,   1,   0,   0, 200,   7,   0,   2,   0,   4],\n",
       "         [  2,   0,   1,  10,   0,   0,  38,  17,   5,   6,   0,   0],\n",
       "         [  0,   1,  11,  24,   1,   0,  14,   3,  13,   6,   0,   1],\n",
       "         [  1,   4,  12,   6,   9,  26,  60,   5,   0,  74,   3,   1],\n",
       "         [  1,  68,  52,   0,   1,   0,  20,   0,   0,   2, 141,   0],\n",
       "         [  0,   2,   0,   0,  44,   0,   0,   0,   0,   0,   0,   3]]),\n",
       "  0.5652767077689352,\n",
       "  0.6573394495412844),\n",
       " ('ConvLSTM',\n",
       "  False,\n",
       "  False,\n",
       "  array([[198,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0, 183,  23,   0,   0,   0,   0,   0,   0,   0,  16,   0],\n",
       "         [  0,  17, 143,   0,   0,   0,   0,   0,   0,   6,  14,   0],\n",
       "         [  0,   0,   0, 259,   0,   0,   0,   8,   2,   0,   0,   0],\n",
       "         [  0,   0,   0,   0, 197,   0,   2,   0,   4,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0, 197,   1,   1,   2,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0, 219,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,  79,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   1,   0,   0,   0,  18,  54,   1,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   7,   0,   0,   0, 180,  14,   0],\n",
       "         [  0,   6,   1,   0,   0,   0,   0,   0,   0,   0, 278,   0],\n",
       "         [  0,   0,   0,   0,   6,   0,   0,   1,   0,   0,   0,  42]]),\n",
       "  0.9171255068012295,\n",
       "  0.9307339449541284),\n",
       " ('ConvLSTM',\n",
       "  False,\n",
       "  True,\n",
       "  array([[198,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  2, 197,  23,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,  28, 141,   0,   0,   0,   0,   0,   0,   5,   6,   0],\n",
       "         [  0,   0,   0, 269,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0, 191,   0,  12,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   5,   0, 190,   0,   0,   2,   4,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0, 219,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,  79,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   4,   0,   0,   2,   2,  65,   1,   0,   0],\n",
       "         [  0,   7,   0,   0,   0,  22,   3,   5,   0, 159,   5,   0],\n",
       "         [  0,  38,  10,   0,   0,   1,   3,   3,   0,  17, 213,   0],\n",
       "         [  0,   0,   0,   0,  45,   0,   1,   0,   0,   0,   0,   3]]),\n",
       "  0.8295595083479173,\n",
       "  0.8825688073394495),\n",
       " ('ConvLSTM',\n",
       "  True,\n",
       "  False,\n",
       "  array([[198,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0, 200,  22,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   9, 160,   0,   0,   0,   0,   0,   0,   0,  11,   0],\n",
       "         [  0,   0,   0, 267,   0,   0,   0,   2,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0, 203,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0, 191,   0,   3,   7,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0, 219,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,  79,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   2,  71,   0,   1,   0],\n",
       "         [  0,   1,   2,   0,   0,   1,   0,   0,   0, 186,  11,   0],\n",
       "         [  0,   8,   1,   0,   0,   0,   0,   0,   0,   0, 276,   0],\n",
       "         [  0,   0,   0,   0,   2,   0,   0,   0,   0,   0,   0,  47]]),\n",
       "  0.9605482376662476,\n",
       "  0.9619266055045872),\n",
       " ('ConvLSTM',\n",
       "  True,\n",
       "  True,\n",
       "  array([[198,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0, 183,  24,   0,   0,   0,   0,   0,   0,  15,   0,   0],\n",
       "         [  0,   8, 146,   1,   0,   0,   0,   0,   0,  20,   5,   0],\n",
       "         [  0,   0,   0, 269,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0, 203,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   9,   0, 191,   1,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0, 219,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   1,   0,   0,   0,  78,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,  15,   0,   0,   2,  11,  46,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,  12,   0,   0,   0, 183,   6,   0],\n",
       "         [  0,   0,   6,   0,   0,   0,   0,   0,   0,  55, 224,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   3,   0,   0,   0,   0,  46]]),\n",
       "  0.907475377051727,\n",
       "  0.9110091743119266)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TfLite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Froze 20 variables.\n",
      "INFO:tensorflow:Converted 20 variables to const ops.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3548632"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow import lite\n",
    "\n",
    "saved_model = os.path.join(model_dir,'best_CNN_dTrue_bnTrue.hdf5')\n",
    "converter = lite.TFLiteConverter.from_keras_model_file(saved_model)\n",
    "converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]\n",
    "tflite_quant_model = converter.convert()\n",
    "open(os.path.join(model_dir,\"converted_model.tflite\"), \"wb\").write(tflite_quant_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.3239154e-03 7.7557907e-04 3.3450004e-04 2.2552563e-03 3.7168426e-04\n",
      "  6.0071298e-03 4.6179453e-03 1.3001963e-05 3.0252317e-04 8.0053258e-01\n",
      "  1.8018529e-01 3.2804930e-03]]\n"
     ]
    }
   ],
   "source": [
    "# Load TFLite model and allocate tensors.\n",
    "interpreter = tf.lite.Interpreter(model_path = os.path.join(model_dir,\"converted_model.tflite\"))\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get input and output tensors.\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "# Test model on random input data.\n",
    "input_shape = input_details[0]['shape']\n",
    "#input_data = np.array(np.random.random_sample(input_shape), dtype=np.float32)\n",
    "input_data = np.array(np.expand_dims(X_test[0], axis=0), dtype=np.float32)\n",
    "interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "\n",
    "interpreter.invoke()\n",
    "output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "print(output_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test model on test data.\n",
    "y_pred = []\n",
    "for i,input_sample in enumerate(X_test):\n",
    "    input_data = np.array(np.expand_dims(input_sample, axis=0), dtype=np.float32)\n",
    "    interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "    interpreter.invoke()\n",
    "    output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "    y_pred.append(np.argmax(output_data, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy after quantization : 0.8463302752293578\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "print(f'Accuracy after quantization : {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
